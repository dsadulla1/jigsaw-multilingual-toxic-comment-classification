{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yi9E6gwR6bw"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "attachments": {
    "186676f7-f9d2-4727-a904-889751b9f6b6.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:186676f7-f9d2-4727-a904-889751b9f6b6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PhXEkPQNR6bx"
   },
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V07\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "MODEL_NAME = 'distilbert' # options include 'xlm' or 'distilbert'\n",
    "\n",
    "NUM_EPOCHS = [2, 2, 1]\n",
    "LR = 5e-5\n",
    "MAX_SEQ_LEN = 75\n",
    "SAMPLE_SIZE = 3000\n",
    "PSUEDO_PROB_THRESH_LOW = 0.05\n",
    "PSUEDO_PROB_THRESH_HIGH = 0.65\n",
    "\n",
    "RUN_ON_SAMPLE = 0\n",
    "ON_KAGGLE = False\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    BATCH_SIZE = 64\n",
    "    PREDICT_BATCH_SIZE = 1024\n",
    "else:\n",
    "    BATCH_SIZE = 16\n",
    "    PREDICT_BATCH_SIZE = 256\n",
    "\n",
    "TRAIN_SPLIT_RATIO = 0.2\n",
    "DROPOUT = 0.3\n",
    "LABEL_SMOOTHING_PARAM = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vBSH2FLlR6b1"
   },
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    RESULTS_DIR = '../working/'\n",
    "    DATA_DIR = '../input/jigsaw-multilingual-toxic-comment-classification/'\n",
    "    if MODEL_NAME == 'xlm':\n",
    "        MODEL_DIR = '../input/tf-xlm-roberta-base/'\n",
    "    else:\n",
    "        MODEL_DIR = '../input/tf-distilbert-base-multilingual-cased/'\n",
    "else:\n",
    "    PATH = \"..\" #\"/content/drive/My Drive/Kaggle/jigsaw-multilingual-toxic-comment-classification\"\n",
    "    RESULTS_DIR = PATH+\"/results/\"\n",
    "    DATA_DIR = PATH+\"/data/\"\n",
    "    if MODEL_NAME == 'xlm':\n",
    "        MODEL_DIR = PATH+\"/models/tf-xlm-roberta-base/\"\n",
    "    else:\n",
    "        MODEL_DIR = PATH+\"/models/distilbert-base-multilingual-cased/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCnsk-7nR6b4"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oW_oT4SZR6b5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold, LeaveOneGroupOut\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys, re, json, gc\n",
    "from time import time, ctime\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D, Softmax, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Activation, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector, Multiply, Layer, LeakyReLU, Subtract\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tokenizers, transformers\n",
    "from transformers import *\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers import TriangularCyclicalLearningRate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pXbm0XVcR6b8"
   },
   "outputs": [],
   "source": [
    "seeded_value = 654123\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.random.seed(seeded_value)\n",
    "tf.random.set_seed(seeded_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ybWWTMP8R6cA",
    "outputId": "c26e2379-92f7-4bcb-bd93-a07825d058f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 19 16:06:29 2020\n"
     ]
    }
   ],
   "source": [
    "print(ctime(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ESteN4q4TAAW",
    "outputId": "a6428c7d-4959-486c-9c24-5dc489c8e04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.1.0', '2.8.0', '0.5.2']\n"
     ]
    }
   ],
   "source": [
    "print([\n",
    "    tf.__version__,\n",
    "    transformers.__version__,\n",
    "    tokenizers.__version__\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR4HCYGTR6cG"
   },
   "source": [
    "<a href=\"https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\"  target=\"_blank\"><h2 id=\"limiting_gpu_memory_growth\" data-text=\"Limiting GPU memory growth\" tabindex=\"0\">Limiting GPU memory growth</h2></a>\n",
    "<p>By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to\n",
    "<a href=\"https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\"><code translate=\"no\" dir=\"ltr\">CUDA_VISIBLE_DEVICES</code></a>) visible to the process. This is done to more efficiently use the relatively precious GPU memory resources on the devices by reducing memory fragmentation. To limit TensorFlow to a specific set of GPUs we use the <code translate=\"no\" dir=\"ltr\">tf.config.experimental.set_visible_devices</code> method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sJh7lbL1R6cH",
    "outputId": "68c74149-67dc-4a43-9d9d-8cec23e054d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.experimental.list_logical_devices('CPU'))\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "print(tf.config.experimental.list_physical_devices('CPU'))\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iAdsW80fR6cL"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQ8ZRVGTR6cO"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wQ_YumuXR6cO"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR+'jigsaw-toxic-comment-train.csv')\n",
    "validation = pd.read_csv(DATA_DIR+'validation.csv')\n",
    "test = pd.read_csv(DATA_DIR+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5Chd2u5AR6cR"
   },
   "outputs": [],
   "source": [
    "train['lang'] = 'en'\n",
    "\n",
    "train['set'] = 'train'\n",
    "validation['set'] = 'valid'\n",
    "test['set'] = 'test'\n",
    "\n",
    "test['toxic'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pZIaKjKXR6cU",
    "outputId": "f2b9d702-b64c-4838-bbcc-b92a243a8e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate', 'lang', 'set'],\n",
      "      dtype='object')\n",
      "Index(['id', 'comment_text', 'lang', 'toxic', 'set'], dtype='object')\n",
      "Index(['id', 'content', 'lang', 'set', 'toxic'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(validation.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['es', 'it', 'tr'], dtype=object),\n",
       " array(['tr', 'ru', 'it', 'fr', 'pt', 'es'], dtype=object))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.lang.unique(), test.lang.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sNlk-kDDR6cY"
   },
   "outputs": [],
   "source": [
    "train.columns = ['id', 'text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'lang', 'set']\n",
    "validation.columns = ['id', 'text', 'lang', 'toxic', 'set']\n",
    "test.columns = ['id', 'text', 'lang', 'set', 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "saymbsyYR6ca"
   },
   "outputs": [],
   "source": [
    "REQ_COLS = ['id', 'set', 'text', 'lang', 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train[\"text\"].astype(str)\n",
    "validation['text'] = validation[\"text\"].astype(str)\n",
    "test['text'] = test[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2VCNIC95R6cf"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train[REQ_COLS].sample(SAMPLE_SIZE, random_state=seeded_value),\n",
    "                  validation[REQ_COLS]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-EPYDkCNR6ci",
    "outputId": "d36606e0-9c8d-4e2a-d2f8-82d4c9f15590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UlrDxcmLR6cl",
    "outputId": "7436086b-4453-44a1-d6be-627e2bd63171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205996</th>\n",
       "      <td>b8e77c1e7bc44922</td>\n",
       "      <td>train</td>\n",
       "      <td>:::Please read my comments at the top of this page. Bye.</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>5397</td>\n",
       "      <td>valid</td>\n",
       "      <td>Sağol ama bu değil. Geçmişte maddenin benim tarafından açılıp ilk önce 50 civarında katkı yaptığım gözükmesi gerekirdi:-/ Neyse boşver. selamlar    Erdall</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id    set  \\\n",
       "205996  b8e77c1e7bc44922  train   \n",
       "5397                5397  valid   \n",
       "\n",
       "                                                                                                                                                                  text  \\\n",
       "205996                                                                                                        :::Please read my comments at the top of this page. Bye.   \n",
       "5397    Sağol ama bu değil. Geçmişte maddenin benim tarafından açılıp ilk önce 50 civarında katkı yaptığım gözükmesi gerekirdi:-/ Neyse boşver. selamlar    Erdall       \n",
       "\n",
       "       lang  toxic  \n",
       "205996   en      0  \n",
       "5397     tr      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CpA5ibkQR6cn",
    "outputId": "dfd2a1f9-d403-43fb-edae-9ca8be5784dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <th>en</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">valid</th>\n",
       "      <th>es</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     toxic\n",
       "set   lang                \n",
       "train en    3000  0.098000\n",
       "valid es    2500  0.168800\n",
       "      it    2500  0.195200\n",
       "      tr    3000  0.106667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "57X-txA_raVA",
    "outputId": "3830e4ae-e5f9-4ab5-a689-050b25913c48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>es</th>\n",
       "      <td>8438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>10920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>11012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>10948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>14000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  toxic\n",
       "set  lang              \n",
       "test es     8438      0\n",
       "     fr    10920      0\n",
       "     it     8494      0\n",
       "     pt    11012      0\n",
       "     ru    10948      0\n",
       "     tr    14000      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ON_SAMPLE>0:\n",
    "    data = data.sample(RUN_ON_SAMPLE).copy().reset_index(drop=True)\n",
    "    test = test.sample(RUN_ON_SAMPLE).copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LLX9UbtR6ct"
   },
   "source": [
    "# Tokenizer, Config & Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnjg9vXYR6cu"
   },
   "source": [
    "1. https://arxiv.org/pdf/1911.02116.pdf\n",
    "2. https://huggingface.co/transformers/model_doc/xlmroberta.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5Z0gl2gTR6cu"
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == 'xlm':\n",
    "    xlmr_tok = transformers.XLMRobertaTokenizer.from_pretrained(MODEL_DIR)\n",
    "else:\n",
    "    xlmr_tok = transformers.DistilBertTokenizer.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4ufXbNlyR6cy",
    "outputId": "58b13fa9-0347-40fe-9809-5a61db9ce3e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(MODEL_DIR+\"special_tokens_map.json\") as f:\n",
    "    special_tokens = json.load(f)\n",
    "xlmr_tok.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "W6qX9qMMR6c0",
    "outputId": "c81308f3-9c5b-4723-b4fc-fd7efdd76c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119547\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = xlmr_tok.vocab_size\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtEkdI5cR6c6"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens, X_att = [], []\n",
    "for t in data.text.tolist():\n",
    "    encoded_text = xlmr_tok.encode_plus(t, pad_to_max_length=True, max_length=MAX_SEQ_LEN)\n",
    "    X_tokens.append(encoded_text['input_ids'])\n",
    "    X_att.append(encoded_text['attention_mask'])\n",
    "\n",
    "X_tokens, X_att, X_lang, Y_toxic = np.array(X_tokens), np.array(X_att), data['lang'].values, data['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "s_cU7WAAxHjS",
    "outputId": "66058960-fec0-46a7-ecb5-a75bb7cbb6e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (63812, 75) \t: X_tokens_test  \n",
      " (63812, 75) \t: X_att_test  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_tokens_test, X_att_test = [], []\n",
    "for t in test.text.tolist():\n",
    "    encoded_text = xlmr_tok.encode_plus(t, pad_to_max_length=True, max_length=MAX_SEQ_LEN)\n",
    "    X_tokens_test.append(encoded_text['input_ids'])\n",
    "    X_att_test.append(encoded_text['attention_mask'])\n",
    "\n",
    "X_tokens_test, X_att_test = np.array(X_tokens_test), np.array(X_att_test)\n",
    "\n",
    "print(\"\\n\",\n",
    "      X_tokens_test.shape, \"\\t: X_tokens_test \", \"\\n\",\n",
    "      X_att_test.shape, \"\\t: X_att_test \", \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DATA_DIR+\"ProcessedData.pickle\"):\n",
    "    with open(DATA_DIR+\"ProcessedData.pickle\", \"rb\") as f:\n",
    "        pickle.dump((X_tokens, X_att, X_lang, Y_toxic, X_tokens_test, X_att_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DATA_DIR+\"ProcessedData.pickle\"):\n",
    "    with open(DATA_DIR+\"ProcessedData.pickle\", \"rb\") as f:\n",
    "        X_tokens, X_att, X_lang, Y_toxic, X_tokens_test, X_att_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeR6DmO2R6dN"
   },
   "source": [
    "# Model Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PKWwyFjzR6dN"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_sequences = Input((MAX_SEQ_LEN), dtype=tf.int32, name=\"words\")\n",
    "    input_att_flags = Input((MAX_SEQ_LEN), dtype=tf.int32, name=\"att_flags\")\n",
    "    \n",
    "    if MODEL_NAME == 'xlm':\n",
    "        config = transformers.XLMRobertaConfig.from_pretrained(MODEL_DIR)\n",
    "        model = transformers.TFXLMRobertaModel.from_pretrained(MODEL_DIR, config=config) # TFXLMRobertaForSequenceClassification\n",
    "        x = model(inputs=input_sequences, attention_mask=input_att_flags)\n",
    "    else:\n",
    "        config = transformers.DistilBertConfig.from_pretrained(MODEL_DIR)\n",
    "        model = transformers.TFDistilBertModel.from_pretrained(MODEL_DIR) # TFDistilBertForSequenceClassification\n",
    "        x = model(inputs=input_sequences, attention_mask=input_att_flags)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(DROPOUT)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(768, 2, padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    toxic_output = tf.keras.layers.Activation('sigmoid', name=\"toxic_output\")(x1)\n",
    "    \n",
    "    model = Model([input_att_flags, input_sequences],\n",
    "                  [toxic_output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "n-x9lurmR6dQ"
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ugXKFEnqR6dT",
    "outputId": "2c509dc7-da68-4adc-f9d6-9c9151b0fad8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "att_flags (InputLayer)          [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB ((None, 75, 768),)   134734080   words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 75, 768)      0           tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 75, 768)      1180416     dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 75, 768)      3072        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 75, 768)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 75, 1)        769         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 75, 1)        4           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 75, 1)        0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 75)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            76          flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "toxic_output (Activation)       (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 135,918,417\n",
      "Trainable params: 135,916,879\n",
      "Non-trainable params: 1,538\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold Stratified train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_FOLDS = 3\n",
    "#skf = StratifiedKFold(NUM_FOLDS, shuffle=True, random_state=seeded_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave one language out split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logo = LeaveOneGroupOut()\n",
    "#for t_index, v_index in logo.split(np.arange(X_tokens.shape[0]), np.arange(X_tokens.shape[0]), groups=X_lang):\n",
    "#    print(X_lang[t_index])\n",
    "#    #print(np.unique(X_lang[v_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple random train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_index, v_index = train_test_split(np.arange(X_tokens.shape[0]), shuffle=True, random_state=seeded_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeR6DmO2R6dN"
   },
   "source": [
    "# Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GGb6IwuR6dY"
   },
   "source": [
    "<a href=\"https://keras.io/guides/transfer_learning/#finetuning\" target=\"_blank\"><h2 id=\"finetuning\">Fine-tuning</h2></a>\n",
    "<p>Once your model has converged on the new data, you can try to unfreeze all or part of\n",
    " the base model and retrain the whole model end-to-end with a very low learning rate.</p>\n",
    " <p>This is an optional last step that can potentially give you incremental improvements.\n",
    " It could also potentially lead to quick overfitting -- keep that in mind.</p>\n",
    " <p>It is critical to only do this step <em>after</em> the model with frozen layers has been\n",
    "trained to convergence. If you mix randomly-initialized trainable layers with\n",
    "trainable layers that hold pre-trained features, the randomly-initialized layers will\n",
    "cause very large gradient updates during training, which will destroy your pre-trained\n",
    " features.</p>\n",
    " <p>It's also critical to use a very low learning rate at this stage, because\n",
    "you are training a much larger model than in the first round of training, on a dataset\n",
    " that is typically very small.\n",
    "As a result, you are at risk of overfitting very quickly if you apply large weight\n",
    " updates. Here, you only want to readapt the pretrained weights in an incremental way.</p>\n",
    "\n",
    "<a href=\"https://keras.io/guides/transfer_learning/#finetuning\" target=\"_blank\"><p><strong>Important note about <code>compile()</code> and <code>trainable</code></strong></p></a>\n",
    "<p>Calling <code>compile()</code> on a model is meant to \"freeze\" the behavior of that model. This\n",
    " implies that the <code>trainable</code>\n",
    "attribute values at the time the model is compiled should be preserved throughout the\n",
    " lifetime of that model,\n",
    "until <code>compile</code> is called again. Hence, if you change any <code>trainable</code> value, make sure\n",
    " to call <code>compile()</code> again on your\n",
    "model for your changes to be taken into account.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((len(X_tokens), 1))\n",
    "pred_test = np.zeros((len(X_tokens_test), 1))\n",
    "timings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8250 samples, validate on 2750 samples\n",
      "Epoch 1/2\n",
      "8250/8250 [==============================] - 123s 15ms/sample - loss: 0.4276 - accuracy: 0.8588 - auc: 0.7772 - val_loss: 0.4307 - val_accuracy: 0.8629 - val_auc: 0.8193\n",
      "Epoch 2/2\n",
      "8250/8250 [==============================] - 110s 13ms/sample - loss: 0.3357 - accuracy: 0.9105 - auc: 0.9333 - val_loss: 0.3749 - val_accuracy: 0.8905 - val_auc: 0.9113\n"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "valid_lang='all'\n",
    "start_time = time()\n",
    "\n",
    "if num>0:\n",
    "    del model\n",
    "    del mcp\n",
    "    del csvl\n",
    "    del adam\n",
    "    del history\n",
    "    del auc\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "\n",
    "model = build_model()\n",
    "auc = tf.keras.metrics.AUC()\n",
    "mcp = ModelCheckpoint(filepath=RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+valid_lang+\"_\"+str(num)+\".h5\", monitor='val_auc',\n",
    "                      verbose=0, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')\n",
    "csvl = CSVLogger(filename=RESULTS_DIR+MODEL_PREFIX+\"_LossLogs_\"+valid_lang+\"_\"+str(num)+\".csv\",\n",
    "                 separator=\",\", append=True)\n",
    "\n",
    "model.layers[3].trainable = False\n",
    "adam = Adam(learning_rate=LR)\n",
    "model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', auc])\n",
    "\n",
    "train_time = time()\n",
    "history = model.fit(x={\"att_flags\":X_att[t_index],\n",
    "                       \"words\":X_tokens[t_index]},\n",
    "                    y={\"toxic_output\":Y_toxic[t_index]},\n",
    "                    validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                      \"words\":X_tokens[v_index]},\n",
    "                                     {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[0],\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[mcp, csvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9892527722785376\n",
      "Valid ROC-AUC:\t 0.9112622350819755\n",
      "Train Accuracy:\t 0.9585454545454546\n",
      "Valid Accuracy:\t 0.8905454545454545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      7113\n",
      "           1       0.81      0.92      0.86      1137\n",
      "\n",
      "    accuracy                           0.96      8250\n",
      "   macro avg       0.90      0.94      0.92      8250\n",
      "weighted avg       0.96      0.96      0.96      8250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      2363\n",
      "           1       0.60      0.68      0.64       387\n",
      "\n",
      "    accuracy                           0.89      2750\n",
      "   macro avg       0.77      0.80      0.79      2750\n",
      "weighted avg       0.90      0.89      0.89      2750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_initial = model.predict(x = {\"att_flags\":X_att,\n",
    "                                  \"words\":X_tokens},\n",
    "                             batch_size=PREDICT_BATCH_SIZE)\n",
    "\n",
    "print(\"Train ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[t_index], y_score=pred_initial[t_index]))\n",
    "print(\"Valid ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[v_index], y_score=pred_initial[v_index]))\n",
    "\n",
    "print(\"Train Accuracy:\\t\", accuracy_score(y_true=Y_toxic[t_index], y_pred=np.where(pred_initial[t_index]>0.5, 1, 0)))\n",
    "print(\"Valid Accuracy:\\t\", accuracy_score(y_true=Y_toxic[v_index], y_pred=np.where(pred_initial[v_index]>0.5, 1, 0)))\n",
    "\n",
    "print(classification_report(y_true=Y_toxic[t_index], y_pred=np.where(pred_initial[t_index]>0.5, 1, 0)))\n",
    "print(classification_report(y_true=Y_toxic[v_index], y_pred=np.where(pred_initial[v_index]>0.5, 1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [],
   "source": [
    "# Psuedo model fit\n",
    "psuedo_time = time()\n",
    "\n",
    "# Accumulate test results after training every fold\n",
    "pred_psuedo = model.predict(x = {\"att_flags\":X_att_test,\n",
    "                                 \"words\":X_tokens_test},\n",
    "                            batch_size=PREDICT_BATCH_SIZE).reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['toxic'] = pred_psuedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    63812.000000\n",
       "mean         0.282639\n",
       "std          0.245812\n",
       "min          0.011453\n",
       "25%          0.105366\n",
       "50%          0.179497\n",
       "75%          0.377658\n",
       "max          0.943357\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['toxic'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>es</th>\n",
       "      <td>8438</td>\n",
       "      <td>0.328209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>10920</td>\n",
       "      <td>0.313224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8494</td>\n",
       "      <td>0.339528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>11012</td>\n",
       "      <td>0.268778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>10948</td>\n",
       "      <td>0.255230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>14000</td>\n",
       "      <td>0.229127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     toxic\n",
       "set  lang                 \n",
       "test es     8438  0.328209\n",
       "     fr    10920  0.313224\n",
       "     it     8494  0.339528\n",
       "     pt    11012  0.268778\n",
       "     ru    10948  0.255230\n",
       "     tr    14000  0.229127"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"48\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">es</th>\n",
       "      <th>count</th>\n",
       "      <td>8438.000000</td>\n",
       "      <td>8438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32405.344039</td>\n",
       "      <td>0.328209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18373.331400</td>\n",
       "      <td>0.291553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.016353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16665.000000</td>\n",
       "      <td>0.097131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32646.500000</td>\n",
       "      <td>0.184129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48250.250000</td>\n",
       "      <td>0.589129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63811.000000</td>\n",
       "      <td>0.943357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">fr</th>\n",
       "      <th>count</th>\n",
       "      <td>10920.000000</td>\n",
       "      <td>10920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31676.724176</td>\n",
       "      <td>0.313224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18378.065199</td>\n",
       "      <td>0.242692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.024004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15838.500000</td>\n",
       "      <td>0.133062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31451.500000</td>\n",
       "      <td>0.212880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47618.750000</td>\n",
       "      <td>0.435619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63800.000000</td>\n",
       "      <td>0.941028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">it</th>\n",
       "      <th>count</th>\n",
       "      <td>8494.000000</td>\n",
       "      <td>8494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31916.568048</td>\n",
       "      <td>0.339528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18416.472108</td>\n",
       "      <td>0.269539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.018956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16118.000000</td>\n",
       "      <td>0.122305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31959.500000</td>\n",
       "      <td>0.229749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47677.250000</td>\n",
       "      <td>0.542318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63809.000000</td>\n",
       "      <td>0.940357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">pt</th>\n",
       "      <th>count</th>\n",
       "      <td>11012.000000</td>\n",
       "      <td>11012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31795.557937</td>\n",
       "      <td>0.268777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18540.963518</td>\n",
       "      <td>0.231364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.023072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15683.750000</td>\n",
       "      <td>0.107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31609.000000</td>\n",
       "      <td>0.169088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47991.500000</td>\n",
       "      <td>0.339189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63798.000000</td>\n",
       "      <td>0.937752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">ru</th>\n",
       "      <th>count</th>\n",
       "      <td>10948.000000</td>\n",
       "      <td>10948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31952.666423</td>\n",
       "      <td>0.255230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18307.410026</td>\n",
       "      <td>0.167966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16051.750000</td>\n",
       "      <td>0.139642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32195.000000</td>\n",
       "      <td>0.203541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47751.750000</td>\n",
       "      <td>0.313072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63803.000000</td>\n",
       "      <td>0.936164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">tr</th>\n",
       "      <th>count</th>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31825.560000</td>\n",
       "      <td>0.229128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18477.674436</td>\n",
       "      <td>0.249932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15613.750000</td>\n",
       "      <td>0.072583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31902.500000</td>\n",
       "      <td>0.114556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47873.500000</td>\n",
       "      <td>0.247613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63810.000000</td>\n",
       "      <td>0.940093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id         toxic\n",
       "set  lang                                  \n",
       "test es   count   8438.000000   8438.000000\n",
       "          mean   32405.344039      0.328209\n",
       "          std    18373.331400      0.291553\n",
       "          min        7.000000      0.016353\n",
       "          25%    16665.000000      0.097131\n",
       "          50%    32646.500000      0.184129\n",
       "          75%    48250.250000      0.589129\n",
       "          max    63811.000000      0.943357\n",
       "     fr   count  10920.000000  10920.000000\n",
       "          mean   31676.724176      0.313224\n",
       "          std    18378.065199      0.242692\n",
       "          min        5.000000      0.024004\n",
       "          25%    15838.500000      0.133062\n",
       "          50%    31451.500000      0.212880\n",
       "          75%    47618.750000      0.435619\n",
       "          max    63800.000000      0.941028\n",
       "     it   count   8494.000000   8494.000000\n",
       "          mean   31916.568048      0.339528\n",
       "          std    18416.472108      0.269539\n",
       "          min        2.000000      0.018956\n",
       "          25%    16118.000000      0.122305\n",
       "          50%    31959.500000      0.229749\n",
       "          75%    47677.250000      0.542318\n",
       "          max    63809.000000      0.940357\n",
       "     pt   count  11012.000000  11012.000000\n",
       "          mean   31795.557937      0.268777\n",
       "          std    18540.963518      0.231364\n",
       "          min        6.000000      0.023072\n",
       "          25%    15683.750000      0.107991\n",
       "          50%    31609.000000      0.169088\n",
       "          75%    47991.500000      0.339189\n",
       "          max    63798.000000      0.937752\n",
       "     ru   count  10948.000000  10948.000000\n",
       "          mean   31952.666423      0.255230\n",
       "          std    18307.410026      0.167966\n",
       "          min        1.000000      0.024970\n",
       "          25%    16051.750000      0.139642\n",
       "          50%    32195.000000      0.203541\n",
       "          75%    47751.750000      0.313072\n",
       "          max    63803.000000      0.936164\n",
       "     tr   count  14000.000000  14000.000000\n",
       "          mean   31825.560000      0.229128\n",
       "          std    18477.674436      0.249932\n",
       "          min        0.000000      0.011453\n",
       "          25%    15613.750000      0.072583\n",
       "          50%    31902.500000      0.114556\n",
       "          75%    47873.500000      0.247613\n",
       "          max    63810.000000      0.940093"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).apply(pd.Series.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of psuedo samples available: 11324\n",
      "Psuedo Toxicity: 8805\n",
      "Counter({'tr': 14000, 'pt': 11012, 'ru': 10948, 'fr': 10920, 'it': 8494, 'es': 8438})\n",
      "Counter({'tr': 3020, 'es': 2425, 'it': 1871, 'fr': 1794, 'pt': 1551, 'ru': 663})\n",
      "Train on 19574 samples, validate on 2750 samples\n",
      "Epoch 1/2\n",
      "19568/19574 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.9557 - auc_1: 0.9864WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
      "19574/19574 [==============================] - 255s 13ms/sample - loss: 0.2805 - accuracy: 0.9558 - auc_1: 0.9864 - val_loss: 0.4161 - val_accuracy: 0.8680 - val_auc_1: 0.8921\n",
      "Epoch 2/2\n",
      "19568/19574 [============================>.] - ETA: 0s - loss: 0.2419 - accuracy: 0.9764 - auc_1: 0.9952WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
      "19574/19574 [==============================] - 244s 12ms/sample - loss: 0.2418 - accuracy: 0.9764 - auc_1: 0.9952 - val_loss: 0.4208 - val_accuracy: 0.8844 - val_auc_1: 0.8663\n",
      "Train on 19574 samples, validate on 2750 samples\n",
      "19568/19574 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9937 - auc_1: 0.9995WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
      "19574/19574 [==============================] - 255s 13ms/sample - loss: 0.2115 - accuracy: 0.9937 - auc_1: 0.9995 - val_loss: 0.4459 - val_accuracy: 0.8771 - val_auc_1: 0.8660\n"
     ]
    }
   ],
   "source": [
    "Y_toxic_psuedo = np.where(pred_psuedo >= PSUEDO_PROB_THRESH_HIGH, 1, 0)\n",
    "psuedo_flag = (pred_psuedo >= PSUEDO_PROB_THRESH_HIGH) | (pred_psuedo <= PSUEDO_PROB_THRESH_LOW)\n",
    "\n",
    "print(\"Number of psuedo samples available:\", sum(psuedo_flag))\n",
    "print(\"Psuedo Toxicity:\", sum(Y_toxic_psuedo))\n",
    "print(Counter(test.lang.values))\n",
    "print(Counter(test.lang.values[psuedo_flag]))\n",
    "\n",
    "X_att_psuedo = np.concatenate((X_att[t_index], X_att_test[psuedo_flag]))\n",
    "X_tokens_psuedo = np.concatenate((X_tokens[t_index], X_tokens_test[psuedo_flag]))\n",
    "Y_toxic_psuedo = np.concatenate((Y_toxic[t_index], Y_toxic_psuedo[psuedo_flag]))\n",
    "\n",
    "shuffled_idxs = np.arange(Y_toxic_psuedo.shape[0])\n",
    "np.random.shuffle(shuffled_idxs)\n",
    "\n",
    "auc = tf.keras.metrics.AUC()\n",
    "mcp = ModelCheckpoint(filepath=RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+valid_lang+\"_\"+str(num)+\".h5\", monitor='val_auc',\n",
    "                      verbose=0, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')\n",
    "csvl = CSVLogger(filename=RESULTS_DIR+MODEL_PREFIX+\"_LossLogs_\"+valid_lang+\"_\"+str(num)+\".csv\",\n",
    "                 separator=\",\", append=True)\n",
    "\n",
    "model.layers[3].trainable = False\n",
    "adam = Adam(learning_rate=LR)\n",
    "model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', auc])\n",
    "\n",
    "history = model.fit(x={\"att_flags\":X_att_psuedo[shuffled_idxs],\n",
    "                       \"words\":X_tokens_psuedo[shuffled_idxs]},\n",
    "                    y={\"toxic_output\":Y_toxic_psuedo[shuffled_idxs]},\n",
    "                    validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                      \"words\":X_tokens[v_index]},\n",
    "                                     {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[1],\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[mcp, csvl])\n",
    "\n",
    "model.layers[3].trainable = True\n",
    "adam = Adam(learning_rate=LR*0.1)\n",
    "model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', auc])\n",
    "\n",
    "history = model.fit(x={\"att_flags\":X_att_psuedo[shuffled_idxs],\n",
    "                       \"words\":X_tokens_psuedo[shuffled_idxs]},\n",
    "                    y={\"toxic_output\":Y_toxic_psuedo[shuffled_idxs]},\n",
    "                    validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                      \"words\":X_tokens[v_index]},\n",
    "                                     {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[2],\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[mcp, csvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9892527722785376\n",
      "Valid ROC-AUC:\t 0.9112622350819755\n",
      "Train Accuracy:\t 0.9585454545454546\n",
      "Valid Accuracy:\t 0.8905454545454545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      7113\n",
      "           1       0.81      0.92      0.86      1137\n",
      "\n",
      "    accuracy                           0.96      8250\n",
      "   macro avg       0.90      0.94      0.92      8250\n",
      "weighted avg       0.96      0.96      0.96      8250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      2363\n",
      "           1       0.60      0.68      0.64       387\n",
      "\n",
      "    accuracy                           0.89      2750\n",
      "   macro avg       0.77      0.80      0.79      2750\n",
      "weighted avg       0.90      0.89      0.89      2750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infer_time = time()\n",
    "\n",
    "# Loading best weights per fold\n",
    "model.load_weights(RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+valid_lang+\"_\"+str(num)+\".h5\")\n",
    "\n",
    "pred += model.predict(x = {\"att_flags\":X_att,\n",
    "                                \"words\":X_tokens},\n",
    "                           batch_size=PREDICT_BATCH_SIZE)\n",
    "\n",
    "print(\"Train ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[t_index], y_score=pred[t_index]))\n",
    "print(\"Valid ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[v_index], y_score=pred[v_index]))\n",
    "\n",
    "print(\"Train Accuracy:\\t\", accuracy_score(y_true=Y_toxic[t_index], y_pred=np.where(pred[t_index]>0.5, 1, 0)))\n",
    "print(\"Valid Accuracy:\\t\", accuracy_score(y_true=Y_toxic[v_index], y_pred=np.where(pred[v_index]>0.5, 1, 0)))\n",
    "\n",
    "print(classification_report(y_true=Y_toxic[t_index], y_pred=np.where(pred[t_index]>0.5, 1, 0)))\n",
    "print(classification_report(y_true=Y_toxic[v_index], y_pred=np.where(pred[v_index]>0.5, 1, 0)))\n",
    "\n",
    "# Accumulate test results after training every fold\n",
    "\n",
    "pred_test += model.predict(x = {\"att_flags\":X_att_test,\n",
    "                                \"words\":X_tokens_test},\n",
    "                           batch_size=PREDICT_BATCH_SIZE)\n",
    "\n",
    "end_time = time()\n",
    "timings_dict.update({num:{\n",
    "    'start_time' : ctime(start_time),\n",
    "    'train_time' : ctime(train_time),\n",
    "    'infer_time' : ctime(infer_time),\n",
    "    'psuedo_time' : ctime(psuedo_time),\n",
    "    'end_time' : ctime(end_time),\n",
    "}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>Fri Jun 19 16:31:17 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infer_time</th>\n",
       "      <td>Fri Jun 19 16:28:17 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psuedo_time</th>\n",
       "      <td>Fri Jun 19 16:13:12 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>Fri Jun 19 16:08:49 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>Fri Jun 19 16:08:52 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "end_time     Fri Jun 19 16:31:17 2020\n",
       "infer_time   Fri Jun 19 16:28:17 2020\n",
       "psuedo_time  Fri Jun 19 16:13:12 2020\n",
       "start_time   Fri Jun 19 16:08:49 2020\n",
       "train_time   Fri Jun 19 16:08:52 2020"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(timings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['toxic'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id','toxic']].to_csv(RESULTS_DIR+\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    63812.000000\n",
       "mean         0.282636\n",
       "std          0.245812\n",
       "min          0.011453\n",
       "25%          0.105366\n",
       "50%          0.179497\n",
       "75%          0.377658\n",
       "max          0.943357\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['toxic'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>es</th>\n",
       "      <td>8438</td>\n",
       "      <td>0.328209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>10920</td>\n",
       "      <td>0.313224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8494</td>\n",
       "      <td>0.339528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>11012</td>\n",
       "      <td>0.268778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>10948</td>\n",
       "      <td>0.255230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>14000</td>\n",
       "      <td>0.229127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     toxic\n",
       "set  lang                 \n",
       "test es     8438  0.328209\n",
       "     fr    10920  0.313224\n",
       "     it     8494  0.339528\n",
       "     pt    11012  0.268778\n",
       "     ru    10948  0.255230\n",
       "     tr    14000  0.229127"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"48\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">es</th>\n",
       "      <th>count</th>\n",
       "      <td>8438.000000</td>\n",
       "      <td>8438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32405.344039</td>\n",
       "      <td>0.328209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18373.331400</td>\n",
       "      <td>0.291553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.016353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16665.000000</td>\n",
       "      <td>0.097131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32646.500000</td>\n",
       "      <td>0.184129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48250.250000</td>\n",
       "      <td>0.589129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63811.000000</td>\n",
       "      <td>0.943357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">fr</th>\n",
       "      <th>count</th>\n",
       "      <td>10920.000000</td>\n",
       "      <td>10920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31676.724176</td>\n",
       "      <td>0.313224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18378.065199</td>\n",
       "      <td>0.242692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.024004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15838.500000</td>\n",
       "      <td>0.133062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31451.500000</td>\n",
       "      <td>0.212880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47618.750000</td>\n",
       "      <td>0.435619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63800.000000</td>\n",
       "      <td>0.941028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">it</th>\n",
       "      <th>count</th>\n",
       "      <td>8494.000000</td>\n",
       "      <td>8494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31916.568048</td>\n",
       "      <td>0.339528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18416.472108</td>\n",
       "      <td>0.269539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.018956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16118.000000</td>\n",
       "      <td>0.122305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31959.500000</td>\n",
       "      <td>0.229749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47677.250000</td>\n",
       "      <td>0.542318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63809.000000</td>\n",
       "      <td>0.940357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">pt</th>\n",
       "      <th>count</th>\n",
       "      <td>11012.000000</td>\n",
       "      <td>11012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31795.557937</td>\n",
       "      <td>0.268778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18540.963518</td>\n",
       "      <td>0.231365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.023072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15683.750000</td>\n",
       "      <td>0.107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31609.000000</td>\n",
       "      <td>0.169088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47991.500000</td>\n",
       "      <td>0.339189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63798.000000</td>\n",
       "      <td>0.937752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">ru</th>\n",
       "      <th>count</th>\n",
       "      <td>10948.000000</td>\n",
       "      <td>10948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31952.666423</td>\n",
       "      <td>0.255230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18307.410026</td>\n",
       "      <td>0.167966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16051.750000</td>\n",
       "      <td>0.139642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32195.000000</td>\n",
       "      <td>0.203541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47751.750000</td>\n",
       "      <td>0.313072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63803.000000</td>\n",
       "      <td>0.936164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">tr</th>\n",
       "      <th>count</th>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31825.560000</td>\n",
       "      <td>0.229127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18477.674436</td>\n",
       "      <td>0.249932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15613.750000</td>\n",
       "      <td>0.072583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31902.500000</td>\n",
       "      <td>0.114556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47873.500000</td>\n",
       "      <td>0.247613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63810.000000</td>\n",
       "      <td>0.940093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id         toxic\n",
       "set  lang                                  \n",
       "test es   count   8438.000000   8438.000000\n",
       "          mean   32405.344039      0.328209\n",
       "          std    18373.331400      0.291553\n",
       "          min        7.000000      0.016353\n",
       "          25%    16665.000000      0.097131\n",
       "          50%    32646.500000      0.184129\n",
       "          75%    48250.250000      0.589129\n",
       "          max    63811.000000      0.943357\n",
       "     fr   count  10920.000000  10920.000000\n",
       "          mean   31676.724176      0.313224\n",
       "          std    18378.065199      0.242692\n",
       "          min        5.000000      0.024004\n",
       "          25%    15838.500000      0.133062\n",
       "          50%    31451.500000      0.212880\n",
       "          75%    47618.750000      0.435619\n",
       "          max    63800.000000      0.941028\n",
       "     it   count   8494.000000   8494.000000\n",
       "          mean   31916.568048      0.339528\n",
       "          std    18416.472108      0.269539\n",
       "          min        2.000000      0.018956\n",
       "          25%    16118.000000      0.122305\n",
       "          50%    31959.500000      0.229749\n",
       "          75%    47677.250000      0.542318\n",
       "          max    63809.000000      0.940357\n",
       "     pt   count  11012.000000  11012.000000\n",
       "          mean   31795.557937      0.268778\n",
       "          std    18540.963518      0.231365\n",
       "          min        6.000000      0.023072\n",
       "          25%    15683.750000      0.107991\n",
       "          50%    31609.000000      0.169088\n",
       "          75%    47991.500000      0.339189\n",
       "          max    63798.000000      0.937752\n",
       "     ru   count  10948.000000  10948.000000\n",
       "          mean   31952.666423      0.255230\n",
       "          std    18307.410026      0.167966\n",
       "          min        1.000000      0.024970\n",
       "          25%    16051.750000      0.139642\n",
       "          50%    32195.000000      0.203541\n",
       "          75%    47751.750000      0.313072\n",
       "          max    63803.000000      0.936164\n",
       "     tr   count  14000.000000  14000.000000\n",
       "          mean   31825.560000      0.229127\n",
       "          std    18477.674436      0.249932\n",
       "          min        0.000000      0.011453\n",
       "          25%    15613.750000      0.072583\n",
       "          50%    31902.500000      0.114556\n",
       "          75%    47873.500000      0.247613\n",
       "          max    63810.000000      0.940093"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).apply(pd.Series.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Mr6qXyMSR6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 19 16:31:18 2020\n"
     ]
    }
   ],
   "source": [
    "print(ctime(time()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
