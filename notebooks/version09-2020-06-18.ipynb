{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yi9E6gwR6bw"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "attachments": {
    "186676f7-f9d2-4727-a904-889751b9f6b6.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:186676f7-f9d2-4727-a904-889751b9f6b6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PhXEkPQNR6bx"
   },
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V09\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "MODEL_NAME = 'distilbert' # options include 'xlm' or 'distilbert'\n",
    "\n",
    "NUM_EPOCHS = [2, 2, 1]\n",
    "LR = 5e-5\n",
    "MAX_SEQ_LEN = 75\n",
    "SAMPLE_SIZE = 8000\n",
    "PSUEDO_PROB_THRESH_LOW = 0.04\n",
    "PSUEDO_PROB_THRESH_HIGH = 0.85\n",
    "\n",
    "RUN_ON_SAMPLE = 0\n",
    "ON_KAGGLE = False\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    BATCH_SIZE = 64\n",
    "    PREDICT_BATCH_SIZE = 1024\n",
    "else:\n",
    "    BATCH_SIZE = 16\n",
    "    PREDICT_BATCH_SIZE = 256\n",
    "\n",
    "TRAIN_SPLIT_RATIO = 0.2\n",
    "DROPOUT = 0.3\n",
    "LABEL_SMOOTHING_PARAM = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vBSH2FLlR6b1"
   },
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    RESULTS_DIR = '../working/'\n",
    "    DATA_DIR = '../input/jigsaw-multilingual-toxic-comment-classification/'\n",
    "    if MODEL_NAME == 'xlm':\n",
    "        MODEL_DIR = '../input/tf-xlm-roberta-base/'\n",
    "    else:\n",
    "        MODEL_DIR = '../input/tf-distilbert-base-multilingual-cased/'\n",
    "else:\n",
    "    PATH = \"..\" #\"/content/drive/My Drive/Kaggle/jigsaw-multilingual-toxic-comment-classification\"\n",
    "    RESULTS_DIR = PATH+\"/results/\"\n",
    "    DATA_DIR = PATH+\"/data/\"\n",
    "    if MODEL_NAME == 'xlm':\n",
    "        MODEL_DIR = PATH+\"/models/tf-xlm-roberta-base/\"\n",
    "    else:\n",
    "        MODEL_DIR = PATH+\"/models/distilbert-base-multilingual-cased/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCnsk-7nR6b4"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oW_oT4SZR6b5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold, LeaveOneGroupOut\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys, re, json, gc\n",
    "from time import time, ctime\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D, Softmax, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Activation, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector, Multiply, Layer, LeakyReLU, Subtract\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tokenizers, transformers\n",
    "from transformers import *\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers import TriangularCyclicalLearningRate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pXbm0XVcR6b8"
   },
   "outputs": [],
   "source": [
    "seeded_value = 654123\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.random.seed(seeded_value)\n",
    "tf.random.set_seed(seeded_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ybWWTMP8R6cA",
    "outputId": "c26e2379-92f7-4bcb-bd93-a07825d058f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 19 19:33:02 2020\n"
     ]
    }
   ],
   "source": [
    "print(ctime(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ESteN4q4TAAW",
    "outputId": "a6428c7d-4959-486c-9c24-5dc489c8e04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.1.0', '2.8.0', '0.5.2']\n"
     ]
    }
   ],
   "source": [
    "print([\n",
    "    tf.__version__,\n",
    "    transformers.__version__,\n",
    "    tokenizers.__version__\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR4HCYGTR6cG"
   },
   "source": [
    "<a href=\"https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\"  target=\"_blank\"><h2 id=\"limiting_gpu_memory_growth\" data-text=\"Limiting GPU memory growth\" tabindex=\"0\">Limiting GPU memory growth</h2></a>\n",
    "<p>By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to\n",
    "<a href=\"https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\"><code translate=\"no\" dir=\"ltr\">CUDA_VISIBLE_DEVICES</code></a>) visible to the process. This is done to more efficiently use the relatively precious GPU memory resources on the devices by reducing memory fragmentation. To limit TensorFlow to a specific set of GPUs we use the <code translate=\"no\" dir=\"ltr\">tf.config.experimental.set_visible_devices</code> method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sJh7lbL1R6cH",
    "outputId": "68c74149-67dc-4a43-9d9d-8cec23e054d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.experimental.list_logical_devices('CPU'))\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "print(tf.config.experimental.list_physical_devices('CPU'))\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iAdsW80fR6cL"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQ8ZRVGTR6cO"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wQ_YumuXR6cO"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR+'jigsaw-toxic-comment-train.csv')\n",
    "validation = pd.read_csv(DATA_DIR+'validation.csv')\n",
    "test = pd.read_csv(DATA_DIR+'test.csv')\n",
    "hate_speech = pd.read_csv(DATA_DIR+\"extra/hate-speech-dataset-multi-language/cleaned_data_hatespeech.csv\")\n",
    "subtitles = pd.read_csv(DATA_DIR+\"extra/open-subtitles-kaggle-dataset/open-subtitles-synthesic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5Chd2u5AR6cR"
   },
   "outputs": [],
   "source": [
    "hate_speech['id'] = np.arange(len(hate_speech))\n",
    "hate_speech['set'] = 'hate_speech'\n",
    "\n",
    "subtitles['set'] = 'subtitles'\n",
    "\n",
    "train['lang'] = 'en'\n",
    "\n",
    "train['set'] = 'train'\n",
    "validation['set'] = 'valid'\n",
    "test['set'] = 'test'\n",
    "\n",
    "test['toxic'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pZIaKjKXR6cU",
    "outputId": "f2b9d702-b64c-4838-bbcc-b92a243a8e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate', 'lang', 'set'],\n",
      "      dtype='object')\n",
      "Index(['id', 'comment_text', 'lang', 'toxic', 'set'], dtype='object')\n",
      "Index(['id', 'content', 'lang', 'set', 'toxic'], dtype='object')\n",
      "Index(['comment_text', 'toxic', 'lang', 'id', 'set'], dtype='object')\n",
      "Index(['id', 'comment_text', 'toxic', 'lang', 'token_length', 'set'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(validation.columns)\n",
    "print(test.columns)\n",
    "print(hate_speech.columns)\n",
    "print(subtitles.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['en'], dtype=object),\n",
       " array(['es', 'it', 'tr'], dtype=object),\n",
       " array(['tr', 'ru', 'it', 'fr', 'pt', 'es'], dtype=object),\n",
       " array(['fr', 'en', 'it', 'tr', 'es', 'ru', 'pt'], dtype=object),\n",
       " array(['fr', 'pt', 'es', 'tr', 'ru', 'it'], dtype=object))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.lang.unique(), validation.lang.unique(), test.lang.unique(), hate_speech.lang.unique(), subtitles.lang.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sNlk-kDDR6cY"
   },
   "outputs": [],
   "source": [
    "train.columns = ['id', 'text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'lang', 'set']\n",
    "validation.columns = ['id', 'text', 'lang', 'toxic', 'set']\n",
    "test.columns = ['id', 'text', 'lang', 'set', 'toxic']\n",
    "hate_speech.columns = ['text', 'toxic', 'lang', 'id', 'set']\n",
    "subtitles.columns = ['id', 'text', 'toxic', 'lang', 'token_length', 'set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "saymbsyYR6ca"
   },
   "outputs": [],
   "source": [
    "REQ_COLS = ['id', 'set', 'text', 'lang', 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train[\"text\"].astype(str)\n",
    "validation['text'] = validation[\"text\"].astype(str)\n",
    "test['text'] = test[\"text\"].astype(str)\n",
    "hate_speech['text'] = hate_speech['text'].astype(str)\n",
    "subtitles['text'] = subtitles['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((223549, 10), (8000, 5), (63812, 5), (117382, 5), (1291949, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validation.shape, test.shape, hate_speech.shape, subtitles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2VCNIC95R6cf"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train[REQ_COLS].sample(SAMPLE_SIZE, random_state=seeded_value),\n",
    "                  validation[REQ_COLS], \n",
    "                  subtitles[REQ_COLS].sample(SAMPLE_SIZE*3, random_state=seeded_value)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-EPYDkCNR6ci",
    "outputId": "d36606e0-9c8d-4e2a-d2f8-82d4c9f15590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26000, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UlrDxcmLR6cl",
    "outputId": "7436086b-4453-44a1-d6be-627e2bd63171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1196711</th>\n",
       "      <td>en-tr-3876281</td>\n",
       "      <td>subtitles</td>\n",
       "      <td>burası Bai Yuan tapınağı değil mi?</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>5618</td>\n",
       "      <td>valid</td>\n",
       "      <td>TODO: Bueno, falta terminar algunas definiciones.... Falta darle un formato mas amigable... La sección de enlaces hay que saber que agregar. Quamer.</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        set  \\\n",
       "1196711  en-tr-3876281  subtitles   \n",
       "5618              5618      valid   \n",
       "\n",
       "                                                                                                                                                         text  \\\n",
       "1196711                                                                                                                    burası Bai Yuan tapınağı değil mi?   \n",
       "5618     TODO: Bueno, falta terminar algunas definiciones.... Falta darle un formato mas amigable... La sección de enlaces hay que saber que agregar. Quamer.   \n",
       "\n",
       "        lang  toxic  \n",
       "1196711   tr      0  \n",
       "5618      es      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "CpA5ibkQR6cn",
    "outputId": "dfd2a1f9-d403-43fb-edae-9ca8be5784dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">subtitles</th>\n",
       "      <th>es</th>\n",
       "      <td>2084</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>2239</td>\n",
       "      <td>0.127289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1048</td>\n",
       "      <td>0.112595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>2927</td>\n",
       "      <td>0.096003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>4202</td>\n",
       "      <td>0.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <th>en</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">valid</th>\n",
       "      <th>es</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     toxic\n",
       "set       lang                \n",
       "subtitles es    2084  0.123800\n",
       "          fr    2239  0.127289\n",
       "          it    1048  0.112595\n",
       "          pt    2500  0.115600\n",
       "          ru    2927  0.096003\n",
       "          tr    4202  0.110900\n",
       "train     en    3000  0.098000\n",
       "valid     es    2500  0.168800\n",
       "          it    2500  0.195200\n",
       "          tr    3000  0.106667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "57X-txA_raVA",
    "outputId": "3830e4ae-e5f9-4ab5-a689-050b25913c48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>es</th>\n",
       "      <td>8438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>10920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>11012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>10948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>14000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  toxic\n",
       "set  lang              \n",
       "test es     8438      0\n",
       "     fr    10920      0\n",
       "     it     8494      0\n",
       "     pt    11012      0\n",
       "     ru    10948      0\n",
       "     tr    14000      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ON_SAMPLE>0:\n",
    "    data = data.sample(RUN_ON_SAMPLE).copy().reset_index(drop=True)\n",
    "    test = test.sample(RUN_ON_SAMPLE).copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LLX9UbtR6ct"
   },
   "source": [
    "# Tokenizer, Config & Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnjg9vXYR6cu"
   },
   "source": [
    "1. https://arxiv.org/pdf/1911.02116.pdf\n",
    "2. https://huggingface.co/transformers/model_doc/xlmroberta.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5Z0gl2gTR6cu"
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == 'xlm':\n",
    "    xlmr_tok = transformers.XLMRobertaTokenizer.from_pretrained(MODEL_DIR)\n",
    "else:\n",
    "    xlmr_tok = transformers.DistilBertTokenizer.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4ufXbNlyR6cy",
    "outputId": "58b13fa9-0347-40fe-9809-5a61db9ce3e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(MODEL_DIR+\"special_tokens_map.json\") as f:\n",
    "    special_tokens = json.load(f)\n",
    "xlmr_tok.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "W6qX9qMMR6c0",
    "outputId": "c81308f3-9c5b-4723-b4fc-fd7efdd76c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119547\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = xlmr_tok.vocab_size\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtEkdI5cR6c6"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens, X_att = [], []\n",
    "for t in data.text.tolist():\n",
    "    encoded_text = xlmr_tok.encode_plus(t, pad_to_max_length=True, max_length=MAX_SEQ_LEN)\n",
    "    X_tokens.append(encoded_text['input_ids'])\n",
    "    X_att.append(encoded_text['attention_mask'])\n",
    "\n",
    "X_tokens, X_att, X_lang, Y_toxic, X_set = np.array(X_tokens), np.array(X_att), data['lang'].values, data['toxic'].values, data['set'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "s_cU7WAAxHjS",
    "outputId": "66058960-fec0-46a7-ecb5-a75bb7cbb6e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (63812, 75) \t: X_tokens_test  \n",
      " (63812, 75) \t: X_att_test  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_tokens_test, X_att_test = [], []\n",
    "for t in test.text.tolist():\n",
    "    encoded_text = xlmr_tok.encode_plus(t, pad_to_max_length=True, max_length=MAX_SEQ_LEN)\n",
    "    X_tokens_test.append(encoded_text['input_ids'])\n",
    "    X_att_test.append(encoded_text['attention_mask'])\n",
    "\n",
    "X_tokens_test, X_att_test = np.array(X_tokens_test), np.array(X_att_test)\n",
    "\n",
    "print(\"\\n\",\n",
    "      X_tokens_test.shape, \"\\t: X_tokens_test \", \"\\n\",\n",
    "      X_att_test.shape, \"\\t: X_att_test \", \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_DIR+\"ProcessedData.pickle\"):\n",
    "    with open(DATA_DIR+\"ProcessedData.pickle\", \"wb\") as f:\n",
    "        pickle.dump((X_tokens, X_att, X_lang, Y_toxic, X_set, X_tokens_test, X_att_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DATA_DIR+\"ProcessedData.pickle\"):\n",
    "    with open(DATA_DIR+\"ProcessedData.pickle\", \"rb\") as f:\n",
    "        X_tokens, X_att, X_lang, Y_toxic, X_set, X_tokens_test, X_att_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeR6DmO2R6dN"
   },
   "source": [
    "# Model Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "PKWwyFjzR6dN"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_sequences = Input((MAX_SEQ_LEN), dtype=tf.int32, name=\"words\")\n",
    "    input_att_flags = Input((MAX_SEQ_LEN), dtype=tf.int32, name=\"att_flags\")\n",
    "    \n",
    "    if MODEL_NAME == 'xlm':\n",
    "        config = transformers.XLMRobertaConfig.from_pretrained(MODEL_DIR)\n",
    "        model = transformers.TFXLMRobertaModel.from_pretrained(MODEL_DIR, config=config) # TFXLMRobertaForSequenceClassification\n",
    "        x = model(inputs=input_sequences, attention_mask=input_att_flags)\n",
    "    else:\n",
    "        config = transformers.DistilBertConfig.from_pretrained(MODEL_DIR)\n",
    "        model = transformers.TFDistilBertModel.from_pretrained(MODEL_DIR) # TFDistilBertForSequenceClassification\n",
    "        x = model(inputs=input_sequences, attention_mask=input_att_flags)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(DROPOUT)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(768, 2, padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    toxic_output = tf.keras.layers.Activation('sigmoid', name=\"toxic_output\")(x1)\n",
    "    \n",
    "    model = Model([input_att_flags, input_sequences],\n",
    "                  [toxic_output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "n-x9lurmR6dQ"
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ugXKFEnqR6dT",
    "outputId": "2c509dc7-da68-4adc-f9d6-9c9151b0fad8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "att_flags (InputLayer)          [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB ((None, 75, 768),)   134734080   words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 75, 768)      0           tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 75, 768)      1180416     dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 75, 768)      3072        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 75, 768)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 75, 1)        769         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 75, 1)        4           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 75, 1)        0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 75)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            76          flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "toxic_output (Activation)       (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 135,918,417\n",
      "Trainable params: 135,916,879\n",
      "Non-trainable params: 1,538\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold Stratified train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_FOLDS = 3\n",
    "#skf = StratifiedKFold(NUM_FOLDS, shuffle=True, random_state=seeded_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave one language out split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logo = LeaveOneGroupOut()\n",
    "#for t_index, v_index in logo.split(np.arange(X_tokens.shape[0]), np.arange(X_tokens.shape[0]), groups=X_lang):\n",
    "#    print(X_lang[t_index])\n",
    "#    #print(np.unique(X_lang[v_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple random train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_index, v_index = train_test_split(np.arange(X_tokens.shape[0]), shuffle=True, random_state=seeded_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000 8000\n"
     ]
    }
   ],
   "source": [
    "t_index, v_index = np.arange(X_tokens.shape[0])[X_set != 'valid'], np.arange(X_tokens.shape[0])[X_set == 'valid']\n",
    "print(len(t_index), len(v_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeR6DmO2R6dN"
   },
   "source": [
    "# Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GGb6IwuR6dY"
   },
   "source": [
    "<a href=\"https://keras.io/guides/transfer_learning/#finetuning\" target=\"_blank\"><h2 id=\"finetuning\">Fine-tuning</h2></a>\n",
    "<p>Once your model has converged on the new data, you can try to unfreeze all or part of\n",
    " the base model and retrain the whole model end-to-end with a very low learning rate.</p>\n",
    " <p>This is an optional last step that can potentially give you incremental improvements.\n",
    " It could also potentially lead to quick overfitting -- keep that in mind.</p>\n",
    " <p>It is critical to only do this step <em>after</em> the model with frozen layers has been\n",
    "trained to convergence. If you mix randomly-initialized trainable layers with\n",
    "trainable layers that hold pre-trained features, the randomly-initialized layers will\n",
    "cause very large gradient updates during training, which will destroy your pre-trained\n",
    " features.</p>\n",
    " <p>It's also critical to use a very low learning rate at this stage, because\n",
    "you are training a much larger model than in the first round of training, on a dataset\n",
    " that is typically very small.\n",
    "As a result, you are at risk of overfitting very quickly if you apply large weight\n",
    " updates. Here, you only want to readapt the pretrained weights in an incremental way.</p>\n",
    "\n",
    "<a href=\"https://keras.io/guides/transfer_learning/#finetuning\" target=\"_blank\"><p><strong>Important note about <code>compile()</code> and <code>trainable</code></strong></p></a>\n",
    "<p>Calling <code>compile()</code> on a model is meant to \"freeze\" the behavior of that model. This\n",
    " implies that the <code>trainable</code>\n",
    "attribute values at the time the model is compiled should be preserved throughout the\n",
    " lifetime of that model,\n",
    "until <code>compile</code> is called again. Hence, if you change any <code>trainable</code> value, make sure\n",
    " to call <code>compile()</code> again on your\n",
    "model for your changes to be taken into account.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((len(X_tokens), 1))\n",
    "pred_test = np.zeros((len(X_tokens_test), 1))\n",
    "timings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 8000 samples\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 228s 13ms/sample - loss: 0.3338 - accuracy: 0.9264 - auc: 0.8882 - val_loss: 0.4531 - val_accuracy: 0.8436 - val_auc: 0.8183\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 220s 12ms/sample - loss: 0.2538 - accuracy: 0.9697 - auc: 0.9776 - val_loss: 0.4215 - val_accuracy: 0.8683 - val_auc: 0.8197\n"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "valid_lang='all'\n",
    "start_time = time()\n",
    "\n",
    "if num>0:\n",
    "    del model\n",
    "    del mcp\n",
    "    del csvl\n",
    "    del adam\n",
    "    del history\n",
    "    del auc\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "\n",
    "model = build_model()\n",
    "auc = tf.keras.metrics.AUC()\n",
    "mcp = ModelCheckpoint(filepath=RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+valid_lang+\"_\"+str(num)+\".h5\", monitor='val_auc',\n",
    "                      verbose=0, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')\n",
    "csvl = CSVLogger(filename=RESULTS_DIR+MODEL_PREFIX+\"_LossLogs_\"+valid_lang+\"_\"+str(num)+\".csv\",\n",
    "                 separator=\",\", append=True)\n",
    "\n",
    "model.layers[3].trainable = False\n",
    "adam = Adam(learning_rate=LR)\n",
    "model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', auc])\n",
    "\n",
    "train_time = time()\n",
    "history = model.fit(x={\"att_flags\":X_att[t_index],\n",
    "                       \"words\":X_tokens[t_index]},\n",
    "                    y={\"toxic_output\":Y_toxic[t_index]},\n",
    "                    validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                      \"words\":X_tokens[v_index]},\n",
    "                                     {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[0],\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[mcp, csvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9977357663486563\n",
      "Valid ROC-AUC:\t 0.8200246184145742\n",
      "Train Accuracy:\t 0.9911111111111112\n",
      "Valid Accuracy:\t 0.86825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     16009\n",
      "           1       0.98      0.94      0.96      1991\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.99      0.97      0.98     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      6770\n",
      "           1       0.64      0.33      0.44      1230\n",
      "\n",
      "    accuracy                           0.87      8000\n",
      "   macro avg       0.76      0.65      0.68      8000\n",
      "weighted avg       0.85      0.87      0.85      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_initial = model.predict(x = {\"att_flags\":X_att,\n",
    "                                  \"words\":X_tokens},\n",
    "                             batch_size=PREDICT_BATCH_SIZE)\n",
    "\n",
    "print(\"Train ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[t_index], y_score=pred_initial[t_index]))\n",
    "print(\"Valid ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[v_index], y_score=pred_initial[v_index]))\n",
    "\n",
    "print(\"Train Accuracy:\\t\", accuracy_score(y_true=Y_toxic[t_index], y_pred=np.where(pred_initial[t_index]>0.5, 1, 0)))\n",
    "print(\"Valid Accuracy:\\t\", accuracy_score(y_true=Y_toxic[v_index], y_pred=np.where(pred_initial[v_index]>0.5, 1, 0)))\n",
    "\n",
    "print(classification_report(y_true=Y_toxic[t_index], y_pred=np.where(pred_initial[t_index]>0.5, 1, 0)))\n",
    "print(classification_report(y_true=Y_toxic[v_index], y_pred=np.where(pred_initial[v_index]>0.5, 1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [],
   "source": [
    "# Psuedo model fit\n",
    "psuedo_time = time()\n",
    "\n",
    "# Accumulate test results after training every fold\n",
    "pred_psuedo = model.predict(x = {\"att_flags\":X_att_test,\n",
    "                                 \"words\":X_tokens_test},\n",
    "                            batch_size=PREDICT_BATCH_SIZE).reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['toxic'] = pred_psuedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    63812.000000\n",
       "mean         0.179727\n",
       "std          0.205050\n",
       "min          0.016896\n",
       "25%          0.070306\n",
       "50%          0.099572\n",
       "75%          0.168248\n",
       "max          0.965636\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['toxic'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>es</th>\n",
       "      <td>8438</td>\n",
       "      <td>0.253663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>10920</td>\n",
       "      <td>0.175282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8494</td>\n",
       "      <td>0.194327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>11012</td>\n",
       "      <td>0.190162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>10948</td>\n",
       "      <td>0.161233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>14000</td>\n",
       "      <td>0.136032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     toxic\n",
       "set  lang                 \n",
       "test es     8438  0.253663\n",
       "     fr    10920  0.175282\n",
       "     it     8494  0.194327\n",
       "     pt    11012  0.190162\n",
       "     ru    10948  0.161233\n",
       "     tr    14000  0.136032"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"48\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">es</th>\n",
       "      <th>count</th>\n",
       "      <td>8438.000000</td>\n",
       "      <td>8438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32405.344039</td>\n",
       "      <td>0.253664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18373.331400</td>\n",
       "      <td>0.276116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.024391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16665.000000</td>\n",
       "      <td>0.068660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32646.500000</td>\n",
       "      <td>0.115258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48250.250000</td>\n",
       "      <td>0.320525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63811.000000</td>\n",
       "      <td>0.965636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">fr</th>\n",
       "      <th>count</th>\n",
       "      <td>10920.000000</td>\n",
       "      <td>10920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31676.724176</td>\n",
       "      <td>0.175283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18378.065199</td>\n",
       "      <td>0.207053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.016896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15838.500000</td>\n",
       "      <td>0.062382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31451.500000</td>\n",
       "      <td>0.090622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47618.750000</td>\n",
       "      <td>0.167141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63800.000000</td>\n",
       "      <td>0.963515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">it</th>\n",
       "      <th>count</th>\n",
       "      <td>8494.000000</td>\n",
       "      <td>8494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31916.568048</td>\n",
       "      <td>0.194327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18416.472108</td>\n",
       "      <td>0.213475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.022080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16118.000000</td>\n",
       "      <td>0.072136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31959.500000</td>\n",
       "      <td>0.107308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47677.250000</td>\n",
       "      <td>0.194433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63809.000000</td>\n",
       "      <td>0.960033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">pt</th>\n",
       "      <th>count</th>\n",
       "      <td>11012.000000</td>\n",
       "      <td>11012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31795.557937</td>\n",
       "      <td>0.190161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18540.963518</td>\n",
       "      <td>0.203421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.020169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15683.750000</td>\n",
       "      <td>0.079254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31609.000000</td>\n",
       "      <td>0.108385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47991.500000</td>\n",
       "      <td>0.183524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63798.000000</td>\n",
       "      <td>0.962209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">ru</th>\n",
       "      <th>count</th>\n",
       "      <td>10948.000000</td>\n",
       "      <td>10948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31952.666423</td>\n",
       "      <td>0.161233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18307.410026</td>\n",
       "      <td>0.180783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16051.750000</td>\n",
       "      <td>0.068504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32195.000000</td>\n",
       "      <td>0.094989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47751.750000</td>\n",
       "      <td>0.145069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63803.000000</td>\n",
       "      <td>0.952820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">tr</th>\n",
       "      <th>count</th>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31825.560000</td>\n",
       "      <td>0.136032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18477.674436</td>\n",
       "      <td>0.144263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15613.750000</td>\n",
       "      <td>0.070320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31902.500000</td>\n",
       "      <td>0.094005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47873.500000</td>\n",
       "      <td>0.130865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63810.000000</td>\n",
       "      <td>0.948377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id         toxic\n",
       "set  lang                                  \n",
       "test es   count   8438.000000   8438.000000\n",
       "          mean   32405.344039      0.253664\n",
       "          std    18373.331400      0.276116\n",
       "          min        7.000000      0.024391\n",
       "          25%    16665.000000      0.068660\n",
       "          50%    32646.500000      0.115258\n",
       "          75%    48250.250000      0.320525\n",
       "          max    63811.000000      0.965636\n",
       "     fr   count  10920.000000  10920.000000\n",
       "          mean   31676.724176      0.175283\n",
       "          std    18378.065199      0.207053\n",
       "          min        5.000000      0.016896\n",
       "          25%    15838.500000      0.062382\n",
       "          50%    31451.500000      0.090622\n",
       "          75%    47618.750000      0.167141\n",
       "          max    63800.000000      0.963515\n",
       "     it   count   8494.000000   8494.000000\n",
       "          mean   31916.568048      0.194327\n",
       "          std    18416.472108      0.213475\n",
       "          min        2.000000      0.022080\n",
       "          25%    16118.000000      0.072136\n",
       "          50%    31959.500000      0.107308\n",
       "          75%    47677.250000      0.194433\n",
       "          max    63809.000000      0.960033\n",
       "     pt   count  11012.000000  11012.000000\n",
       "          mean   31795.557937      0.190161\n",
       "          std    18540.963518      0.203421\n",
       "          min        6.000000      0.020169\n",
       "          25%    15683.750000      0.079254\n",
       "          50%    31609.000000      0.108385\n",
       "          75%    47991.500000      0.183524\n",
       "          max    63798.000000      0.962209\n",
       "     ru   count  10948.000000  10948.000000\n",
       "          mean   31952.666423      0.161233\n",
       "          std    18307.410026      0.180783\n",
       "          min        1.000000      0.024888\n",
       "          25%    16051.750000      0.068504\n",
       "          50%    32195.000000      0.094989\n",
       "          75%    47751.750000      0.145069\n",
       "          max    63803.000000      0.952820\n",
       "     tr   count  14000.000000  14000.000000\n",
       "          mean   31825.560000      0.136032\n",
       "          std    18477.674436      0.144263\n",
       "          min        0.000000      0.020852\n",
       "          25%    15613.750000      0.070320\n",
       "          50%    31902.500000      0.094005\n",
       "          75%    47873.500000      0.130865\n",
       "          max    63810.000000      0.948377"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).apply(pd.Series.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of psuedo samples available: 3272\n",
      "Psuedo Toxicity: 1750\n",
      "Counter({'tr': 14000, 'pt': 11012, 'ru': 10948, 'fr': 10920, 'it': 8494, 'es': 8438})\n",
      "Counter({'es': 931, 'fr': 753, 'it': 423, 'pt': 409, 'ru': 381, 'tr': 375})\n",
      "Train on 21272 samples, validate on 8000 samples\n",
      "Epoch 1/2\n",
      "21272/21272 [==============================] - 289s 14ms/sample - loss: 0.2274 - accuracy: 0.9847 - auc: 0.9950 - val_loss: 0.4792 - val_accuracy: 0.8534 - val_auc: 0.8280\n",
      "Epoch 2/2\n",
      "21272/21272 [==============================] - 277s 13ms/sample - loss: 0.2153 - accuracy: 0.9914 - auc: 0.9983 - val_loss: 0.5702 - val_accuracy: 0.8181 - val_auc: 0.7976\n",
      "Train on 21272 samples, validate on 8000 samples\n",
      "21272/21272 [==============================] - 289s 14ms/sample - loss: 0.2048 - accuracy: 0.9973 - auc: 0.9999 - val_loss: 0.5461 - val_accuracy: 0.8209 - val_auc: 0.7985\n"
     ]
    }
   ],
   "source": [
    "Y_toxic_psuedo = np.where(pred_psuedo >= PSUEDO_PROB_THRESH_HIGH, 1, 0)\n",
    "psuedo_flag = (pred_psuedo >= PSUEDO_PROB_THRESH_HIGH) | (pred_psuedo <= PSUEDO_PROB_THRESH_LOW)\n",
    "\n",
    "print(\"Number of psuedo samples available:\", sum(psuedo_flag))\n",
    "print(\"Psuedo Toxicity:\", sum(Y_toxic_psuedo))\n",
    "print(Counter(test.lang.values))\n",
    "print(Counter(test.lang.values[psuedo_flag]))\n",
    "\n",
    "X_att_psuedo = np.concatenate((X_att[t_index], X_att_test[psuedo_flag]))\n",
    "X_tokens_psuedo = np.concatenate((X_tokens[t_index], X_tokens_test[psuedo_flag]))\n",
    "Y_toxic_psuedo = np.concatenate((Y_toxic[t_index], Y_toxic_psuedo[psuedo_flag]))\n",
    "\n",
    "shuffled_idxs = np.arange(Y_toxic_psuedo.shape[0])\n",
    "np.random.shuffle(shuffled_idxs)\n",
    "\n",
    "model.layers[3].trainable = False\n",
    "adam = Adam(learning_rate=LR)\n",
    "model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', auc])\n",
    "\n",
    "history = model.fit(x={\"att_flags\":X_att_psuedo[shuffled_idxs],\n",
    "                       \"words\":X_tokens_psuedo[shuffled_idxs]},\n",
    "                    y={\"toxic_output\":Y_toxic_psuedo[shuffled_idxs]},\n",
    "                    validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                      \"words\":X_tokens[v_index]},\n",
    "                                     {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[1],\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[mcp, csvl])\n",
    "\n",
    "model.layers[3].trainable = True\n",
    "adam = Adam(learning_rate=LR*0.001)\n",
    "model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', auc])\n",
    "\n",
    "history = model.fit(x={\"att_flags\":X_att_psuedo[shuffled_idxs],\n",
    "                       \"words\":X_tokens_psuedo[shuffled_idxs]},\n",
    "                    y={\"toxic_output\":Y_toxic_psuedo[shuffled_idxs]},\n",
    "                    validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                      \"words\":X_tokens[v_index]},\n",
    "                                     {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[2],\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[mcp, csvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "lpuHmXlWR6dq",
    "outputId": "249a868a-d0a0-482d-965d-e26bd49bff48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9992279895045226\n",
      "Valid ROC-AUC:\t 0.8278962664072725\n",
      "Train Accuracy:\t 0.9944444444444445\n",
      "Valid Accuracy:\t 0.853375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16009\n",
      "           1       0.98      0.97      0.97      1991\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.99      0.98      0.99     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      6770\n",
      "           1       0.52      0.54      0.53      1230\n",
      "\n",
      "    accuracy                           0.85      8000\n",
      "   macro avg       0.72      0.73      0.72      8000\n",
      "weighted avg       0.86      0.85      0.85      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infer_time = time()\n",
    "\n",
    "# Loading best weights per fold\n",
    "model.load_weights(RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+valid_lang+\"_\"+str(num)+\".h5\")\n",
    "\n",
    "pred += model.predict(x = {\"att_flags\":X_att,\n",
    "                                \"words\":X_tokens},\n",
    "                           batch_size=PREDICT_BATCH_SIZE)\n",
    "\n",
    "print(\"Train ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[t_index], y_score=pred[t_index]))\n",
    "print(\"Valid ROC-AUC:\\t\", roc_auc_score(y_true=Y_toxic[v_index], y_score=pred[v_index]))\n",
    "\n",
    "print(\"Train Accuracy:\\t\", accuracy_score(y_true=Y_toxic[t_index], y_pred=np.where(pred[t_index]>0.5, 1, 0)))\n",
    "print(\"Valid Accuracy:\\t\", accuracy_score(y_true=Y_toxic[v_index], y_pred=np.where(pred[v_index]>0.5, 1, 0)))\n",
    "\n",
    "print(classification_report(y_true=Y_toxic[t_index], y_pred=np.where(pred[t_index]>0.5, 1, 0)))\n",
    "print(classification_report(y_true=Y_toxic[v_index], y_pred=np.where(pred[v_index]>0.5, 1, 0)))\n",
    "\n",
    "# Accumulate test results after training every fold\n",
    "\n",
    "pred_test += model.predict(x = {\"att_flags\":X_att_test,\n",
    "                                \"words\":X_tokens_test},\n",
    "                           batch_size=PREDICT_BATCH_SIZE)\n",
    "\n",
    "end_time = time()\n",
    "timings_dict.update({num:{\n",
    "    'start_time' : ctime(start_time),\n",
    "    'train_time' : ctime(train_time),\n",
    "    'infer_time' : ctime(infer_time),\n",
    "    'psuedo_time' : ctime(psuedo_time),\n",
    "    'end_time' : ctime(end_time),\n",
    "}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>Fri Jun 19 20:13:22 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infer_time</th>\n",
       "      <td>Fri Jun 19 20:09:45 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psuedo_time</th>\n",
       "      <td>Fri Jun 19 19:52:58 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>Fri Jun 19 19:44:24 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>Fri Jun 19 19:44:26 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "end_time     Fri Jun 19 20:13:22 2020\n",
       "infer_time   Fri Jun 19 20:09:45 2020\n",
       "psuedo_time  Fri Jun 19 19:52:58 2020\n",
       "start_time   Fri Jun 19 19:44:24 2020\n",
       "train_time   Fri Jun 19 19:44:26 2020"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(timings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['toxic'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id','toxic']].to_csv(RESULTS_DIR+\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    63812.000000\n",
       "mean         0.227771\n",
       "std          0.301072\n",
       "min          0.013343\n",
       "25%          0.053583\n",
       "50%          0.076167\n",
       "75%          0.203183\n",
       "max          0.984382\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['toxic'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>es</th>\n",
       "      <td>8438</td>\n",
       "      <td>0.355292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>10920</td>\n",
       "      <td>0.252624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8494</td>\n",
       "      <td>0.283121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>11012</td>\n",
       "      <td>0.207749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>10948</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>14000</td>\n",
       "      <td>0.129121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     toxic\n",
       "set  lang                 \n",
       "test es     8438  0.355292\n",
       "     fr    10920  0.252624\n",
       "     it     8494  0.283121\n",
       "     pt    11012  0.207749\n",
       "     ru    10948  0.208045\n",
       "     tr    14000  0.129121"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"48\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">es</th>\n",
       "      <th>count</th>\n",
       "      <td>8438.000000</td>\n",
       "      <td>8438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32405.344039</td>\n",
       "      <td>0.355292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18373.331400</td>\n",
       "      <td>0.372974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.013879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16665.000000</td>\n",
       "      <td>0.056060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32646.500000</td>\n",
       "      <td>0.106069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48250.250000</td>\n",
       "      <td>0.778454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63811.000000</td>\n",
       "      <td>0.984071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">fr</th>\n",
       "      <th>count</th>\n",
       "      <td>10920.000000</td>\n",
       "      <td>10920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31676.724176</td>\n",
       "      <td>0.252624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18378.065199</td>\n",
       "      <td>0.324163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.018948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15838.500000</td>\n",
       "      <td>0.049302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31451.500000</td>\n",
       "      <td>0.073242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47618.750000</td>\n",
       "      <td>0.319326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63800.000000</td>\n",
       "      <td>0.984382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">it</th>\n",
       "      <th>count</th>\n",
       "      <td>8494.000000</td>\n",
       "      <td>8494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31916.568048</td>\n",
       "      <td>0.283121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18416.472108</td>\n",
       "      <td>0.332654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.017021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16118.000000</td>\n",
       "      <td>0.057107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31959.500000</td>\n",
       "      <td>0.091229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47677.250000</td>\n",
       "      <td>0.464111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63809.000000</td>\n",
       "      <td>0.983352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">pt</th>\n",
       "      <th>count</th>\n",
       "      <td>11012.000000</td>\n",
       "      <td>11012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31795.557937</td>\n",
       "      <td>0.207749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18540.963518</td>\n",
       "      <td>0.286818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.020407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15683.750000</td>\n",
       "      <td>0.052257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31609.000000</td>\n",
       "      <td>0.070982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47991.500000</td>\n",
       "      <td>0.155167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63798.000000</td>\n",
       "      <td>0.981881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">ru</th>\n",
       "      <th>count</th>\n",
       "      <td>10948.000000</td>\n",
       "      <td>10948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31952.666423</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18307.410026</td>\n",
       "      <td>0.276383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16051.750000</td>\n",
       "      <td>0.054783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32195.000000</td>\n",
       "      <td>0.074878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47751.750000</td>\n",
       "      <td>0.170231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63803.000000</td>\n",
       "      <td>0.982071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">tr</th>\n",
       "      <th>count</th>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31825.560000</td>\n",
       "      <td>0.129121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18477.674436</td>\n",
       "      <td>0.182503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15613.750000</td>\n",
       "      <td>0.054110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31902.500000</td>\n",
       "      <td>0.072073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47873.500000</td>\n",
       "      <td>0.102602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63810.000000</td>\n",
       "      <td>0.979828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id         toxic\n",
       "set  lang                                  \n",
       "test es   count   8438.000000   8438.000000\n",
       "          mean   32405.344039      0.355292\n",
       "          std    18373.331400      0.372974\n",
       "          min        7.000000      0.013879\n",
       "          25%    16665.000000      0.056060\n",
       "          50%    32646.500000      0.106069\n",
       "          75%    48250.250000      0.778454\n",
       "          max    63811.000000      0.984071\n",
       "     fr   count  10920.000000  10920.000000\n",
       "          mean   31676.724176      0.252624\n",
       "          std    18378.065199      0.324163\n",
       "          min        5.000000      0.018948\n",
       "          25%    15838.500000      0.049302\n",
       "          50%    31451.500000      0.073242\n",
       "          75%    47618.750000      0.319326\n",
       "          max    63800.000000      0.984382\n",
       "     it   count   8494.000000   8494.000000\n",
       "          mean   31916.568048      0.283121\n",
       "          std    18416.472108      0.332654\n",
       "          min        2.000000      0.017021\n",
       "          25%    16118.000000      0.057107\n",
       "          50%    31959.500000      0.091229\n",
       "          75%    47677.250000      0.464111\n",
       "          max    63809.000000      0.983352\n",
       "     pt   count  11012.000000  11012.000000\n",
       "          mean   31795.557937      0.207749\n",
       "          std    18540.963518      0.286818\n",
       "          min        6.000000      0.020407\n",
       "          25%    15683.750000      0.052257\n",
       "          50%    31609.000000      0.070982\n",
       "          75%    47991.500000      0.155167\n",
       "          max    63798.000000      0.981881\n",
       "     ru   count  10948.000000  10948.000000\n",
       "          mean   31952.666423      0.208045\n",
       "          std    18307.410026      0.276383\n",
       "          min        1.000000      0.018885\n",
       "          25%    16051.750000      0.054783\n",
       "          50%    32195.000000      0.074878\n",
       "          75%    47751.750000      0.170231\n",
       "          max    63803.000000      0.982071\n",
       "     tr   count  14000.000000  14000.000000\n",
       "          mean   31825.560000      0.129121\n",
       "          std    18477.674436      0.182503\n",
       "          min        0.000000      0.013343\n",
       "          25%    15613.750000      0.054110\n",
       "          50%    31902.500000      0.072073\n",
       "          75%    47873.500000      0.102602\n",
       "          max    63810.000000      0.979828"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).apply(pd.Series.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Mr6qXyMSR6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 19 20:13:22 2020\n"
     ]
    }
   ],
   "source": [
    "print(ctime(time()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
