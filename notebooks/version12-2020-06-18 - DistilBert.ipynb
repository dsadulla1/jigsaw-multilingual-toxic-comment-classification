{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changelog:\n",
    "1. Same as V11\n",
    "2. stricter psuedo-label selection\n",
    "3. training without english samples\n",
    "4. triangular cyclical learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yi9E6gwR6bw"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "attachments": {
    "186676f7-f9d2-4727-a904-889751b9f6b6.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:186676f7-f9d2-4727-a904-889751b9f6b6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhXEkPQNR6bx"
   },
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V12\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "MODEL_NAME = 'distilbert' # options include 'xlm' or 'distilbert'\n",
    "\n",
    "NUM_EPOCHS = [32, 32, 2]\n",
    "NUM_FOLDS = 5\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 1e-3\n",
    "STEP_SIZE = 2\n",
    "MAX_SEQ_LEN = 128\n",
    "SAMPLE_SIZE = 6000\n",
    "PSUEDO_QUANTILE_THRESH_HIGH = 0.98\n",
    "PSUEDO_QUANTILE_THRESH_LOW = 0.02\n",
    "\n",
    "RUN_ON_SAMPLE = 0\n",
    "if RUN_ON_SAMPLE>0:\n",
    "    SAMPLE_SIZE = RUN_ON_SAMPLE\n",
    "\n",
    "ON_KAGGLE = False\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    BATCH_SIZE = 32\n",
    "    PREDICT_BATCH_SIZE = 512\n",
    "else:\n",
    "    BATCH_SIZE = 16\n",
    "    PREDICT_BATCH_SIZE = 256\n",
    "\n",
    "TRAIN_SPLIT_RATIO = 0.2\n",
    "DROPOUT = 0.3\n",
    "LABEL_SMOOTHING_PARAM = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBSH2FLlR6b1"
   },
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    RESULTS_DIR = '../working/'\n",
    "    DATA_DIR = '../input/jigsaw-multilingual-toxic-comment-classification/'\n",
    "    if MODEL_NAME == 'xlm':\n",
    "        MODEL_DIR = '../input/tf-xlm-roberta-base/'\n",
    "    else:\n",
    "        MODEL_DIR = '../input/tf-distilbert-base-multilingual-cased/'\n",
    "else:\n",
    "    PATH = \"..\"\n",
    "    RESULTS_DIR = PATH+\"/results/\"\n",
    "    DATA_DIR = PATH+\"/data/\"\n",
    "    if MODEL_NAME == 'xlm':\n",
    "        MODEL_DIR = PATH+\"/models/tf-xlm-roberta-base/\"\n",
    "    else:\n",
    "        MODEL_DIR = PATH+\"/models/distilbert-base-multilingual-cased/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCnsk-7nR6b4"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oW_oT4SZR6b5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold, LeaveOneGroupOut\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys, re, json, gc\n",
    "from time import time, ctime\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D, Softmax, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Activation, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector, Multiply, Layer, LeakyReLU, Subtract\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tokenizers, transformers\n",
    "from transformers import *\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers import TriangularCyclicalLearningRate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pXbm0XVcR6b8"
   },
   "outputs": [],
   "source": [
    "seeded_value = 987258\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.random.seed(seeded_value)\n",
    "tf.random.set_seed(seeded_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ybWWTMP8R6cA",
    "outputId": "c26e2379-92f7-4bcb-bd93-a07825d058f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 21 07:50:59 2020\n"
     ]
    }
   ],
   "source": [
    "print(ctime(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ESteN4q4TAAW",
    "outputId": "a6428c7d-4959-486c-9c24-5dc489c8e04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.1.0', '2.8.0', '0.5.2']\n"
     ]
    }
   ],
   "source": [
    "print([\n",
    "    tf.__version__,\n",
    "    transformers.__version__,\n",
    "    tokenizers.__version__\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR4HCYGTR6cG"
   },
   "source": [
    "<a href=\"https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\"  target=\"_blank\"><h2 id=\"limiting_gpu_memory_growth\" data-text=\"Limiting GPU memory growth\" tabindex=\"0\">Limiting GPU memory growth</h2></a>\n",
    "<p>By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to\n",
    "<a href=\"https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\"><code translate=\"no\" dir=\"ltr\">CUDA_VISIBLE_DEVICES</code></a>) visible to the process. This is done to more efficiently use the relatively precious GPU memory resources on the devices by reducing memory fragmentation. To limit TensorFlow to a specific set of GPUs we use the <code translate=\"no\" dir=\"ltr\">tf.config.experimental.set_visible_devices</code> method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sJh7lbL1R6cH",
    "outputId": "68c74149-67dc-4a43-9d9d-8cec23e054d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.experimental.list_logical_devices('CPU'))\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "print(tf.config.experimental.list_physical_devices('CPU'))\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iAdsW80fR6cL"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQ8ZRVGTR6cO"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wQ_YumuXR6cO"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR+'jigsaw-toxic-comment-train.csv')\n",
    "validation = pd.read_csv(DATA_DIR+'validation.csv')\n",
    "test = pd.read_csv(DATA_DIR+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5Chd2u5AR6cR"
   },
   "outputs": [],
   "source": [
    "train['lang'] = 'en'\n",
    "\n",
    "train['set'] = 'train'\n",
    "validation['set'] = 'valid'\n",
    "test['set'] = 'test'\n",
    "\n",
    "test['toxic'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pZIaKjKXR6cU",
    "outputId": "f2b9d702-b64c-4838-bbcc-b92a243a8e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate', 'lang', 'set'],\n",
      "      dtype='object')\n",
      "Index(['id', 'comment_text', 'lang', 'toxic', 'set'], dtype='object')\n",
      "Index(['id', 'content', 'lang', 'set', 'toxic'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(validation.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['es', 'it', 'tr'], dtype=object),\n",
       " array(['tr', 'ru', 'it', 'fr', 'pt', 'es'], dtype=object))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.lang.unique(), test.lang.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sNlk-kDDR6cY"
   },
   "outputs": [],
   "source": [
    "train.columns = ['id', 'text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'lang', 'set']\n",
    "validation.columns = ['id', 'text', 'lang', 'toxic', 'set']\n",
    "test.columns = ['id', 'text', 'lang', 'set', 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "saymbsyYR6ca"
   },
   "outputs": [],
   "source": [
    "REQ_COLS = ['id', 'set', 'text', 'lang', 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train[\"text\"].astype(str)\n",
    "validation['text'] = validation[\"text\"].astype(str)\n",
    "test['text'] = test[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2VCNIC95R6cf"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([validation[REQ_COLS]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. XLM-RoBerta uses these special tokens \"sep_token\": \"\\</s\\>\", \"pad_token\": \"\\<pad\\>\", \"cls_token\": \"\\<s\\>\"\n",
    "2. Distilbert uses these special tokens \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    'en':' english',\n",
    "    'tr':' turkish',\n",
    "    'ru':' russian',\n",
    "    'it':' italian',\n",
    "    'fr':' french',\n",
    "    'pt':' portuguese',\n",
    "    'es':' spanish',\n",
    "}\n",
    "\n",
    "if MODEL_NAME == 'xlm':\n",
    "    data['text'] = data['lang'].apply(lambda x:languages[x]) + \" </s> \" + data['text']\n",
    "    test['text'] = test['lang'].apply(lambda x:languages[x]) + \" </s> \" + test['text']\n",
    "else:\n",
    "    data['text'] = data['lang'].apply(lambda x:languages[x]) + \" [SEP] \" + data['text']\n",
    "    test['text'] = test['lang'].apply(lambda x:languages[x]) + \" [SEP] \" + test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-EPYDkCNR6ci",
    "outputId": "d36606e0-9c8d-4e2a-d2f8-82d4c9f15590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UlrDxcmLR6cl",
    "outputId": "7436086b-4453-44a1-d6be-627e2bd63171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>4153</td>\n",
       "      <td>valid</td>\n",
       "      <td>turkish [SEP] İşte ben de diyorum ki Türkçede farklı bir ada sahip olmadığını iddia ediyorsanız muhtemelen konu ilgi alanınızda değil. Kişisel itham olarak algılamayın bir olasılık olarak söylüyorum. Konuya dair yakın dönem Türkçe hangi kaynağa bakarsanız bakın Kobane/Kobani görürsünüz.    Kud      yaz</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>2736</td>\n",
       "      <td>valid</td>\n",
       "      <td>italian [SEP] Continuo anch io a pensare che la frase rispecchia perfettamente il pensiero di Odifreddi, che è quello di cui parla la voce su Odifreddi. Se la voce Adolf Hitler iniziasse con la citazione  gli ebrei sono dei parassiti nel corpo delle altre nazioni  ci sarebbero gli stessi problemi? .mau. ✉</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    set  \\\n",
       "4153  4153  valid   \n",
       "2736  2736  valid   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "4153   turkish [SEP] İşte ben de diyorum ki Türkçede farklı bir ada sahip olmadığını iddia ediyorsanız muhtemelen konu ilgi alanınızda değil. Kişisel itham olarak algılamayın bir olasılık olarak söylüyorum. Konuya dair yakın dönem Türkçe hangi kaynağa bakarsanız bakın Kobane/Kobani görürsünüz.    Kud      yaz       \n",
       "2736   italian [SEP] Continuo anch io a pensare che la frase rispecchia perfettamente il pensiero di Odifreddi, che è quello di cui parla la voce su Odifreddi. Se la voce Adolf Hitler iniziasse con la citazione  gli ebrei sono dei parassiti nel corpo delle altre nazioni  ci sarebbero gli stessi problemi? .mau. ✉    \n",
       "\n",
       "     lang  toxic  \n",
       "4153   tr      0  \n",
       "2736   it      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "CpA5ibkQR6cn",
    "outputId": "dfd2a1f9-d403-43fb-edae-9ca8be5784dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">valid</th>\n",
       "      <th>es</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     toxic\n",
       "set   lang                \n",
       "valid es    2500  0.168800\n",
       "      it    2500  0.195200\n",
       "      tr    3000  0.106667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "57X-txA_raVA",
    "outputId": "3830e4ae-e5f9-4ab5-a689-050b25913c48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>es</th>\n",
       "      <td>8438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>10920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>8494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>11012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>10948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>14000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  toxic\n",
       "set  lang              \n",
       "test es     8438      0\n",
       "     fr    10920      0\n",
       "     it     8494      0\n",
       "     pt    11012      0\n",
       "     ru    10948      0\n",
       "     tr    14000      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"set\", \"lang\"]).agg({'id':'count', 'toxic':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ON_SAMPLE>0:\n",
    "    data = data.sample(RUN_ON_SAMPLE).copy().reset_index(drop=True)\n",
    "    test = test.sample(RUN_ON_SAMPLE).copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LLX9UbtR6ct"
   },
   "source": [
    "# Tokenizer, Config & Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnjg9vXYR6cu"
   },
   "source": [
    "1. https://arxiv.org/pdf/1911.02116.pdf\n",
    "2. https://huggingface.co/transformers/model_doc/xlmroberta.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5Z0gl2gTR6cu"
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == 'xlm':\n",
    "    xlmr_tok = transformers.XLMRobertaTokenizer.from_pretrained(MODEL_DIR)\n",
    "else:\n",
    "    xlmr_tok = transformers.DistilBertTokenizer.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4ufXbNlyR6cy",
    "outputId": "58b13fa9-0347-40fe-9809-5a61db9ce3e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(MODEL_DIR+\"special_tokens_map.json\") as f:\n",
    "    special_tokens = json.load(f)\n",
    "xlmr_tok.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "W6qX9qMMR6c0",
    "outputId": "c81308f3-9c5b-4723-b4fc-fd7efdd76c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119547\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = xlmr_tok.vocab_size\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtEkdI5cR6c6"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens, X_att = [], []\n",
    "\n",
    "for t in data.text.tolist():\n",
    "    encoded_text = xlmr_tok.encode_plus(t, pad_to_max_length=True, max_length=MAX_SEQ_LEN)\n",
    "    X_tokens.append(encoded_text['input_ids'])\n",
    "    X_att.append(encoded_text['attention_mask'])\n",
    "\n",
    "X_tokens, X_att, X_lang, Y_toxic = np.array(X_tokens), np.array(X_att), data['lang'].values, data['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "s_cU7WAAxHjS",
    "outputId": "66058960-fec0-46a7-ecb5-a75bb7cbb6e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (63812, 128) \t: X_tokens_test  \n",
      " (63812, 128) \t: X_att_test  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_tokens_test, X_att_test = [], []\n",
    "\n",
    "for t in test.text.tolist():\n",
    "    encoded_text = xlmr_tok.encode_plus(t, pad_to_max_length=True, max_length=MAX_SEQ_LEN)\n",
    "    X_tokens_test.append(encoded_text['input_ids'])\n",
    "    X_att_test.append(encoded_text['attention_mask'])\n",
    "    \n",
    "X_tokens_test, X_att_test, X_lang_test = np.array(X_tokens_test), np.array(X_att_test), test['lang'].values\n",
    "\n",
    "print(\"\\n\",\n",
    "      X_tokens_test.shape, \"\\t: X_tokens_test \", \"\\n\",\n",
    "      X_att_test.shape, \"\\t: X_att_test \", \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sample Text**\n",
      " spanish [SEP] Este usuario ni siquiera llega al rango de    hereje   . Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión.    Skipe linkin 22px   Honor, valor, leltad.      17:48 13 mar 2008 (UTC)\n",
      "**Encoded Tokens**\n",
      "[101, 51551, 15529, 102, 12515, 82849, 10414, 10294, 39190, 10113, 39492, 10164, 39715, 10104, 19353, 10381, 119, 12399, 10406, 12921, 96621, 10493, 29826, 11272, 10110, 10109, 18121, 10537, 83592, 10220, 32385, 66240, 10198, 39215, 193, 75036, 32500, 18010, 80592, 32413, 11244, 18229, 10198, 11600, 32413, 11482, 119, 51874, 11355, 26192, 10245, 10306, 10410, 10686, 26354, 117, 18094, 117, 10141, 92608, 119, 10273, 131, 11300, 10249, 12318, 10203, 113, 11780, 114, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "**Decoded Tokens**\n",
      "[CLS] spanish [SEP] Este usuario ni siquiera llega al rango de hereje. Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión. Skipe linkin 22px Honor, valor, leltad. 17 : 48 13 mar 2008 ( UTC ) [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(\"**Sample Text**\")\n",
    "t = data['text'][0]\n",
    "encoded_text = xlmr_tok.encode_plus(t, pad_to_max_length=True, max_length=MAX_SEQ_LEN)\n",
    "decoded_tokens = xlmr_tok.decode(encoded_text['input_ids'])\n",
    "print(t)\n",
    "print(\"**Encoded Tokens**\")\n",
    "print(encoded_text['input_ids'], sep=\",\")\n",
    "print(\"**Decoded Tokens**\")\n",
    "print(decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeR6DmO2R6dN"
   },
   "source": [
    "# Model Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PKWwyFjzR6dN"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_sequences = Input((MAX_SEQ_LEN), dtype=tf.int32, name=\"words\")\n",
    "    input_att_flags = Input((MAX_SEQ_LEN), dtype=tf.int32, name=\"att_flags\")\n",
    "    \n",
    "    if MODEL_NAME == 'xlm':\n",
    "        config = transformers.XLMRobertaConfig.from_pretrained(MODEL_DIR)\n",
    "        model = transformers.TFXLMRobertaModel.from_pretrained(MODEL_DIR, config=config) # TFXLMRobertaForSequenceClassification\n",
    "        x = model(inputs=input_sequences, attention_mask=input_att_flags)\n",
    "    else:\n",
    "        config = transformers.DistilBertConfig.from_pretrained(MODEL_DIR)\n",
    "        model = transformers.TFDistilBertModel.from_pretrained(MODEL_DIR, config=config) # TFDistilBertForSequenceClassification\n",
    "        x = model(inputs=input_sequences, attention_mask=input_att_flags)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(DROPOUT)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(768, 2, padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    toxic_output = tf.keras.layers.Activation('sigmoid', name=\"toxic_output\")(x1)\n",
    "    \n",
    "    model = Model([input_att_flags, input_sequences],\n",
    "                  [toxic_output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "n-x9lurmR6dQ"
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ugXKFEnqR6dT",
    "outputId": "2c509dc7-da68-4adc-f9d6-9c9151b0fad8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "att_flags (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB ((None, 128, 768),)  134734080   words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 128, 768)     0           tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 128, 768)     1180416     dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 768)     3072        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 128, 768)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 1)       769         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 1)       4           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 1)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "toxic_output (Activation)       (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 135,918,470\n",
      "Trainable params: 135,916,932\n",
      "Non-trainable params: 1,538\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(NUM_FOLDS, shuffle=True, random_state=seeded_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold Stratified train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skf = StratifiedKFold(NUM_FOLDS, shuffle=True, random_state=seeded_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave one language out split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logo = LeaveOneGroupOut()\n",
    "#for t_index, v_index in logo.split(np.arange(X_tokens.shape[0]), np.arange(X_tokens.shape[0]), groups=X_lang):\n",
    "#    print(X_lang[t_index])\n",
    "#    #print(np.unique(X_lang[v_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple random train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_index, v_index = train_test_split(np.arange(X_tokens.shape[0]), shuffle=True, random_state=seeded_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeR6DmO2R6dN"
   },
   "source": [
    "# Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GGb6IwuR6dY"
   },
   "source": [
    "<a href=\"https://keras.io/guides/transfer_learning/#finetuning\" target=\"_blank\"><h2 id=\"finetuning\">Fine-tuning</h2></a>\n",
    "<p>Once your model has converged on the new data, you can try to unfreeze all or part of\n",
    " the base model and retrain the whole model end-to-end with a very low learning rate.</p>\n",
    " <p>This is an optional last step that can potentially give you incremental improvements.\n",
    " It could also potentially lead to quick overfitting -- keep that in mind.</p>\n",
    " <p>It is critical to only do this step <em>after</em> the model with frozen layers has been\n",
    "trained to convergence. If you mix randomly-initialized trainable layers with\n",
    "trainable layers that hold pre-trained features, the randomly-initialized layers will\n",
    "cause very large gradient updates during training, which will destroy your pre-trained\n",
    " features.</p>\n",
    " <p>It's also critical to use a very low learning rate at this stage, because\n",
    "you are training a much larger model than in the first round of training, on a dataset\n",
    " that is typically very small.\n",
    "As a result, you are at risk of overfitting very quickly if you apply large weight\n",
    " updates. Here, you only want to readapt the pretrained weights in an incremental way.</p>\n",
    "\n",
    "<a href=\"https://keras.io/guides/transfer_learning/#finetuning\" target=\"_blank\"><p><strong>Important note about <code>compile()</code> and <code>trainable</code></strong></p></a>\n",
    "<p>Calling <code>compile()</code> on a model is meant to \"freeze\" the behavior of that model. This\n",
    " implies that the <code>trainable</code>\n",
    "attribute values at the time the model is compiled should be preserved throughout the\n",
    " lifetime of that model,\n",
    "until <code>compile</code> is called again. Hence, if you change any <code>trainable</code> value, make sure\n",
    " to call <code>compile()</code> again on your\n",
    "model for your changes to be taken into account.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = data[['id']]\n",
    "pred_df_test = test[['id']]\n",
    "timings_dict = {}\n",
    "cv_stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ==================== FOLD# 0 ====================\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "6400/6400 [==============================] - 47s 7ms/sample - loss: 0.6214 - accuracy: 0.7020 - auc: 0.5236 - val_loss: 0.4975 - val_accuracy: 0.8375 - val_auc: 0.5948\n",
      "Epoch 2/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4903 - accuracy: 0.8334 - auc: 0.6508 - val_loss: 0.4585 - val_accuracy: 0.8487 - val_auc: 0.7176\n",
      "Epoch 3/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4592 - accuracy: 0.8477 - auc: 0.7354 - val_loss: 0.4416 - val_accuracy: 0.8575 - val_auc: 0.7700\n",
      "Epoch 4/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4454 - accuracy: 0.8505 - auc: 0.7765 - val_loss: 0.4338 - val_accuracy: 0.8619 - val_auc: 0.7867\n",
      "Epoch 5/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4371 - accuracy: 0.8572 - auc: 0.7980 - val_loss: 0.4324 - val_accuracy: 0.8706 - val_auc: 0.7948\n",
      "Epoch 6/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4273 - accuracy: 0.8617 - auc: 0.8205 - val_loss: 0.4338 - val_accuracy: 0.8769 - val_auc: 0.7875\n",
      "Epoch 7/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4242 - accuracy: 0.8625 - auc: 0.8269 - val_loss: 0.4495 - val_accuracy: 0.8631 - val_auc: 0.7927\n",
      "Epoch 8/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4221 - accuracy: 0.8620 - auc: 0.8315 - val_loss: 0.4464 - val_accuracy: 0.8656 - val_auc: 0.7738\n",
      "Epoch 9/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4179 - accuracy: 0.8695 - auc: 0.8379 - val_loss: 0.4276 - val_accuracy: 0.8669 - val_auc: 0.8040\n",
      "Epoch 10/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4170 - accuracy: 0.8689 - auc: 0.8387 - val_loss: 0.4389 - val_accuracy: 0.8681 - val_auc: 0.7774\n",
      "Epoch 11/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4118 - accuracy: 0.8714 - auc: 0.8492 - val_loss: 0.4214 - val_accuracy: 0.8687 - val_auc: 0.8185\n",
      "Epoch 12/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4105 - accuracy: 0.8733 - auc: 0.8515 - val_loss: 0.4209 - val_accuracy: 0.8700 - val_auc: 0.8174\n",
      "Epoch 13/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4066 - accuracy: 0.8727 - auc: 0.8605 - val_loss: 0.4336 - val_accuracy: 0.8569 - val_auc: 0.8097\n",
      "Epoch 14/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4019 - accuracy: 0.8736 - auc: 0.8685 - val_loss: 0.4414 - val_accuracy: 0.8469 - val_auc: 0.8093\n",
      "Epoch 15/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4056 - accuracy: 0.8702 - auc: 0.8625 - val_loss: 0.4323 - val_accuracy: 0.8544 - val_auc: 0.8052\n",
      "Epoch 16/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4010 - accuracy: 0.8770 - auc: 0.8719 - val_loss: 0.4333 - val_accuracy: 0.8687 - val_auc: 0.8083\n",
      "Epoch 17/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3962 - accuracy: 0.8763 - auc: 0.8777 - val_loss: 0.4186 - val_accuracy: 0.8706 - val_auc: 0.8404\n",
      "Epoch 18/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3960 - accuracy: 0.8789 - auc: 0.8770 - val_loss: 0.4376 - val_accuracy: 0.8469 - val_auc: 0.8233\n",
      "Epoch 19/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3972 - accuracy: 0.8764 - auc: 0.8763 - val_loss: 0.4304 - val_accuracy: 0.8587 - val_auc: 0.8248\n",
      "Epoch 20/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3953 - accuracy: 0.8808 - auc: 0.8787 - val_loss: 0.4254 - val_accuracy: 0.8644 - val_auc: 0.8230\n",
      "Epoch 21/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3943 - accuracy: 0.8814 - auc: 0.8806 - val_loss: 0.4230 - val_accuracy: 0.8600 - val_auc: 0.8303\n",
      "Epoch 22/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3926 - accuracy: 0.8802 - auc: 0.8848 - val_loss: 0.4321 - val_accuracy: 0.8712 - val_auc: 0.8160\n",
      "Epoch 23/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3911 - accuracy: 0.8830 - auc: 0.8864 - val_loss: 0.4130 - val_accuracy: 0.8669 - val_auc: 0.8422\n",
      "Epoch 24/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3875 - accuracy: 0.8838 - auc: 0.8919 - val_loss: 0.4319 - val_accuracy: 0.8700 - val_auc: 0.8240\n",
      "Epoch 25/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3886 - accuracy: 0.8841 - auc: 0.8896 - val_loss: 0.4354 - val_accuracy: 0.8506 - val_auc: 0.8255\n",
      "Epoch 26/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3875 - accuracy: 0.8811 - auc: 0.8917 - val_loss: 0.4148 - val_accuracy: 0.8725 - val_auc: 0.8371\n",
      "Epoch 27/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3849 - accuracy: 0.8823 - auc: 0.8975 - val_loss: 0.4260 - val_accuracy: 0.8581 - val_auc: 0.8418\n",
      "Epoch 28/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3830 - accuracy: 0.8869 - auc: 0.8968 - val_loss: 0.4434 - val_accuracy: 0.8550 - val_auc: 0.8225\n",
      "Epoch 29/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3834 - accuracy: 0.8880 - auc: 0.8976 - val_loss: 0.4504 - val_accuracy: 0.8394 - val_auc: 0.8365\n",
      "Epoch 30/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3813 - accuracy: 0.8875 - auc: 0.9005 - val_loss: 0.4137 - val_accuracy: 0.8656 - val_auc: 0.8366\n",
      "Epoch 31/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3823 - accuracy: 0.8848 - auc: 0.9018 - val_loss: 0.4242 - val_accuracy: 0.8637 - val_auc: 0.8431\n",
      "Epoch 32/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3833 - accuracy: 0.8814 - auc: 0.8994 - val_loss: 0.4122 - val_accuracy: 0.8750 - val_auc: 0.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9417124259564248\n",
      "Valid ROC-AUC:\t 0.8431361845756344\n",
      "Train Accuracy:\t 0.89984375\n",
      "Valid Accuracy:\t 0.86375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5413\n",
      "           1       0.83      0.44      0.58       987\n",
      "\n",
      "    accuracy                           0.90      6400\n",
      "   macro avg       0.87      0.71      0.76      6400\n",
      "weighted avg       0.89      0.90      0.89      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1357\n",
      "           1       0.61      0.29      0.39       243\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.75      0.63      0.66      1600\n",
      "weighted avg       0.84      0.86      0.84      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSUEDO_PROB_THRESH_HIGH 0.766\n",
      "PSUEDO_PROB_THRESH_LOW 0.002\n",
      "Number of psuedo samples available: 2554\n",
      "Psuedo Toxicity: 1277\n",
      "Counter({'tr': 14000, 'pt': 11012, 'ru': 10948, 'fr': 10920, 'it': 8494, 'es': 8438})\n",
      "Counter({'pt': 1181, 'fr': 447, 'es': 445, 'tr': 199, 'it': 185, 'ru': 97})\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "8954/8954 [==============================] - 66s 7ms/sample - loss: 0.3308 - accuracy: 0.9155 - auc: 0.9646 - val_loss: 0.4160 - val_accuracy: 0.8687 - val_auc: 0.8415\n",
      "Epoch 2/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2997 - accuracy: 0.9165 - auc: 0.9642 - val_loss: 0.4108 - val_accuracy: 0.8675 - val_auc: 0.8406\n",
      "Epoch 3/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2865 - accuracy: 0.9187 - auc: 0.9671 - val_loss: 0.4109 - val_accuracy: 0.8650 - val_auc: 0.8481\n",
      "Epoch 4/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2886 - accuracy: 0.9208 - auc: 0.9646 - val_loss: 0.4120 - val_accuracy: 0.8706 - val_auc: 0.8431\n",
      "Epoch 5/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2839 - accuracy: 0.9232 - auc: 0.9675 - val_loss: 0.4134 - val_accuracy: 0.8731 - val_auc: 0.8454\n",
      "Epoch 6/32\n",
      "8954/8954 [==============================] - 57s 6ms/sample - loss: 0.2858 - accuracy: 0.9195 - auc: 0.9672 - val_loss: 0.4161 - val_accuracy: 0.8631 - val_auc: 0.8455\n",
      "Epoch 7/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2833 - accuracy: 0.9247 - auc: 0.9686 - val_loss: 0.4208 - val_accuracy: 0.8662 - val_auc: 0.8364\n",
      "Epoch 8/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2831 - accuracy: 0.9232 - auc: 0.9684 - val_loss: 0.4201 - val_accuracy: 0.8694 - val_auc: 0.8330\n",
      "Epoch 9/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2820 - accuracy: 0.9261 - auc: 0.9691 - val_loss: 0.4494 - val_accuracy: 0.8363 - val_auc: 0.8020\n",
      "Epoch 10/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2827 - accuracy: 0.9257 - auc: 0.9697 - val_loss: 0.4284 - val_accuracy: 0.8600 - val_auc: 0.8350\n",
      "Epoch 11/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2837 - accuracy: 0.9234 - auc: 0.9676 - val_loss: 0.4193 - val_accuracy: 0.8744 - val_auc: 0.8239y: 0.9235 - auc: \n",
      "Epoch 12/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2820 - accuracy: 0.9257 - auc: 0.9694 - val_loss: 0.4198 - val_accuracy: 0.8694 - val_auc: 0.8410\n",
      "Epoch 13/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2790 - accuracy: 0.9300 - auc: 0.9724 - val_loss: 0.4188 - val_accuracy: 0.8675 - val_auc: 0.8435\n",
      "Epoch 14/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2809 - accuracy: 0.9271 - auc: 0.9698 - val_loss: 0.4187 - val_accuracy: 0.8556 - val_auc: 0.8418\n",
      "Epoch 15/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2803 - accuracy: 0.9276 - auc: 0.9706 - val_loss: 0.4228 - val_accuracy: 0.8600 - val_auc: 0.8301\n",
      "Epoch 16/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2790 - accuracy: 0.9292 - auc: 0.9713 - val_loss: 0.4332 - val_accuracy: 0.8669 - val_auc: 0.8391\n",
      "Epoch 17/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2804 - accuracy: 0.9268 - auc: 0.9706 - val_loss: 0.4190 - val_accuracy: 0.8662 - val_auc: 0.8366\n",
      "Epoch 18/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2797 - accuracy: 0.9263 - auc: 0.9712 - val_loss: 0.4278 - val_accuracy: 0.8706 - val_auc: 0.8168\n",
      "Epoch 19/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2806 - accuracy: 0.9253 - auc: 0.9693 - val_loss: 0.4335 - val_accuracy: 0.8487 - val_auc: 0.8307\n",
      "Epoch 20/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2799 - accuracy: 0.9283 - auc: 0.9708 - val_loss: 0.4209 - val_accuracy: 0.8631 - val_auc: 0.8314\n",
      "Epoch 21/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2796 - accuracy: 0.9262 - auc: 0.9707 - val_loss: 0.4597 - val_accuracy: 0.8256 - val_auc: 0.8302\n",
      "Epoch 22/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2798 - accuracy: 0.9248 - auc: 0.9705 - val_loss: 0.4359 - val_accuracy: 0.8681 - val_auc: 0.8303\n",
      "Epoch 23/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2799 - accuracy: 0.9280 - auc: 0.9697 - val_loss: 0.4396 - val_accuracy: 0.8775 - val_auc: 0.7961\n",
      "Epoch 24/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2789 - accuracy: 0.9302 - auc: 0.9707 - val_loss: 0.4262 - val_accuracy: 0.8550 - val_auc: 0.8284\n",
      "Epoch 25/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2770 - accuracy: 0.9310 - auc: 0.9726 - val_loss: 0.4271 - val_accuracy: 0.8581 - val_auc: 0.8363\n",
      "Epoch 26/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2766 - accuracy: 0.9273 - auc: 0.9741 - val_loss: 0.4306 - val_accuracy: 0.8587 - val_auc: 0.8258\n",
      "Epoch 27/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2746 - accuracy: 0.9295 - auc: 0.9755 - val_loss: 0.4250 - val_accuracy: 0.8656 - val_auc: 0.8337\n",
      "Epoch 28/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2749 - accuracy: 0.9319 - auc: 0.9755 - val_loss: 0.4419 - val_accuracy: 0.8706 - val_auc: 0.8242\n",
      "Epoch 29/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2717 - accuracy: 0.9342 - auc: 0.9785 - val_loss: 0.4327 - val_accuracy: 0.8544 - val_auc: 0.8253loss: 0.2713 - \n",
      "Epoch 30/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2712 - accuracy: 0.9379 - auc: 0.9781 - val_loss: 0.4272 - val_accuracy: 0.8600 - val_auc: 0.8375\n",
      "Epoch 31/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2705 - accuracy: 0.9350 - auc: 0.9788 - val_loss: 0.4486 - val_accuracy: 0.8744 - val_auc: 0.8315\n",
      "Epoch 32/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2684 - accuracy: 0.9375 - auc: 0.9810 - val_loss: 0.4426 - val_accuracy: 0.8706 - val_auc: 0.8259\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/2\n",
      "8954/8954 [==============================] - 168s 19ms/sample - loss: 0.2864 - accuracy: 0.9220 - auc: 0.9673 - val_loss: 0.4125 - val_accuracy: 0.8687 - val_auc: 0.8476\n",
      "Epoch 2/2\n",
      "8954/8954 [==============================] - 157s 18ms/sample - loss: 0.2860 - accuracy: 0.9233 - auc: 0.9677 - val_loss: 0.4112 - val_accuracy: 0.8687 - val_auc: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9506499700241322\n",
      "Valid ROC-AUC:\t 0.84810660164791\n",
      "Train Accuracy:\t 0.910625\n",
      "Valid Accuracy:\t 0.865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      5413\n",
      "           1       0.78      0.59      0.67       987\n",
      "\n",
      "    accuracy                           0.91      6400\n",
      "   macro avg       0.85      0.78      0.81      6400\n",
      "weighted avg       0.90      0.91      0.91      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1357\n",
      "           1       0.58      0.41      0.48       243\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.74      0.68      0.70      1600\n",
      "weighted avg       0.85      0.86      0.86      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ==================== FOLD# 1 ====================\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "6400/6400 [==============================] - 46s 7ms/sample - loss: 0.5426 - accuracy: 0.7769 - auc: 0.6134 - val_loss: 0.4887 - val_accuracy: 0.8275 - val_auc: 0.7508\n",
      "Epoch 2/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4586 - accuracy: 0.8492 - auc: 0.7367 - val_loss: 0.4476 - val_accuracy: 0.8500 - val_auc: 0.7942\n",
      "Epoch 3/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4379 - accuracy: 0.8578 - auc: 0.7893 - val_loss: 0.4436 - val_accuracy: 0.8487 - val_auc: 0.7954\n",
      "Epoch 4/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4297 - accuracy: 0.8580 - auc: 0.8132 - val_loss: 0.4465 - val_accuracy: 0.8512 - val_auc: 0.7932\n",
      "Epoch 5/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4210 - accuracy: 0.8672 - auc: 0.8285 - val_loss: 0.4451 - val_accuracy: 0.8550 - val_auc: 0.8121\n",
      "Epoch 6/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4191 - accuracy: 0.8658 - auc: 0.8340 - val_loss: 0.4377 - val_accuracy: 0.8519 - val_auc: 0.8120\n",
      "Epoch 7/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4164 - accuracy: 0.8677 - auc: 0.8377 - val_loss: 0.4519 - val_accuracy: 0.8506 - val_auc: 0.7951\n",
      "Epoch 8/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4080 - accuracy: 0.8719 - auc: 0.8545 - val_loss: 0.4453 - val_accuracy: 0.8456 - val_auc: 0.8030\n",
      "Epoch 9/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4106 - accuracy: 0.8717 - auc: 0.8508 - val_loss: 0.4433 - val_accuracy: 0.8519 - val_auc: 0.8139\n",
      "Epoch 10/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4028 - accuracy: 0.8739 - auc: 0.8655 - val_loss: 0.4377 - val_accuracy: 0.8537 - val_auc: 0.8104\n",
      "Epoch 11/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4047 - accuracy: 0.8789 - auc: 0.8579 - val_loss: 0.4315 - val_accuracy: 0.8556 - val_auc: 0.8261\n",
      "Epoch 12/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4046 - accuracy: 0.8744 - auc: 0.8590 - val_loss: 0.4392 - val_accuracy: 0.8500 - val_auc: 0.8152\n",
      "Epoch 13/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4035 - accuracy: 0.8737 - auc: 0.8639 - val_loss: 0.4610 - val_accuracy: 0.8512 - val_auc: 0.8010\n",
      "Epoch 14/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3945 - accuracy: 0.8803 - auc: 0.8787 - val_loss: 0.4311 - val_accuracy: 0.8537 - val_auc: 0.8271\n",
      "Epoch 15/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3921 - accuracy: 0.8816 - auc: 0.8819 - val_loss: 0.4332 - val_accuracy: 0.8556 - val_auc: 0.8316\n",
      "Epoch 16/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3938 - accuracy: 0.8791 - auc: 0.8798 - val_loss: 0.4274 - val_accuracy: 0.8481 - val_auc: 0.8348\n",
      "Epoch 17/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3951 - accuracy: 0.8828 - auc: 0.8748 - val_loss: 0.4545 - val_accuracy: 0.8512 - val_auc: 0.8301\n",
      "Epoch 18/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3935 - accuracy: 0.8794 - auc: 0.8799 - val_loss: 0.4483 - val_accuracy: 0.8494 - val_auc: 0.8172\n",
      "Epoch 19/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3919 - accuracy: 0.8788 - auc: 0.8827 - val_loss: 0.4493 - val_accuracy: 0.8494 - val_auc: 0.8313\n",
      "Epoch 20/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3913 - accuracy: 0.8819 - auc: 0.8825 - val_loss: 0.4331 - val_accuracy: 0.8544 - val_auc: 0.8280\n",
      "Epoch 21/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3881 - accuracy: 0.8845 - auc: 0.8889 - val_loss: 0.4415 - val_accuracy: 0.8369 - val_auc: 0.8254\n",
      "Epoch 22/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3826 - accuracy: 0.8863 - auc: 0.8977 - val_loss: 0.4381 - val_accuracy: 0.8506 - val_auc: 0.8151\n",
      "Epoch 23/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3887 - accuracy: 0.8798 - auc: 0.8900 - val_loss: 0.4379 - val_accuracy: 0.8494 - val_auc: 0.8126\n",
      "Epoch 24/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3831 - accuracy: 0.8842 - auc: 0.8956 - val_loss: 0.4291 - val_accuracy: 0.8512 - val_auc: 0.8320\n",
      "Epoch 25/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3823 - accuracy: 0.8894 - auc: 0.8960 - val_loss: 0.4409 - val_accuracy: 0.8462 - val_auc: 0.8015\n",
      "Epoch 26/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3798 - accuracy: 0.8886 - auc: 0.9013 - val_loss: 0.4440 - val_accuracy: 0.8506 - val_auc: 0.8144\n",
      "Epoch 27/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3792 - accuracy: 0.8913 - auc: 0.9016 - val_loss: 0.4353 - val_accuracy: 0.8419 - val_auc: 0.8222\n",
      "Epoch 28/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3788 - accuracy: 0.8886 - auc: 0.9018 - val_loss: 0.4341 - val_accuracy: 0.8575 - val_auc: 0.8334\n",
      "Epoch 29/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3791 - accuracy: 0.8895 - auc: 0.9024 - val_loss: 0.4300 - val_accuracy: 0.8487 - val_auc: 0.8307\n",
      "Epoch 30/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3804 - accuracy: 0.8919 - auc: 0.8986 - val_loss: 0.4318 - val_accuracy: 0.8537 - val_auc: 0.8228\n",
      "Epoch 31/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3772 - accuracy: 0.8917 - auc: 0.9058 - val_loss: 0.4314 - val_accuracy: 0.8494 - val_auc: 0.8302\n",
      "Epoch 32/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3766 - accuracy: 0.8897 - auc: 0.9056 - val_loss: 0.4357 - val_accuracy: 0.8550 - val_auc: 0.8194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9228388323251259\n",
      "Valid ROC-AUC:\t 0.8350933944933192\n",
      "Train Accuracy:\t 0.89515625\n",
      "Valid Accuracy:\t 0.848125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      5432\n",
      "           1       0.75      0.46      0.57       968\n",
      "\n",
      "    accuracy                           0.90      6400\n",
      "   macro avg       0.83      0.72      0.76      6400\n",
      "weighted avg       0.89      0.90      0.88      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1338\n",
      "           1       0.56      0.34      0.43       262\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.72      0.65      0.67      1600\n",
      "weighted avg       0.83      0.85      0.83      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSUEDO_PROB_THRESH_HIGH 0.78\n",
      "PSUEDO_PROB_THRESH_LOW 0.008\n",
      "Number of psuedo samples available: 2554\n",
      "Psuedo Toxicity: 1277\n",
      "Counter({'tr': 14000, 'pt': 11012, 'ru': 10948, 'fr': 10920, 'it': 8494, 'es': 8438})\n",
      "Counter({'pt': 695, 'es': 659, 'tr': 506, 'fr': 380, 'ru': 161, 'it': 153})\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "8954/8954 [==============================] - 68s 8ms/sample - loss: 0.3133 - accuracy: 0.9132 - auc: 0.9574 - val_loss: 0.4621 - val_accuracy: 0.8481 - val_auc: 0.8390\n",
      "Epoch 2/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2950 - accuracy: 0.9142 - auc: 0.9571 - val_loss: 0.4562 - val_accuracy: 0.8462 - val_auc: 0.8412\n",
      "Epoch 3/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2929 - accuracy: 0.9174 - auc: 0.9561 - val_loss: 0.4311 - val_accuracy: 0.8544 - val_auc: 0.8403\n",
      "Epoch 4/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2910 - accuracy: 0.9120 - auc: 0.9563 - val_loss: 0.4450 - val_accuracy: 0.8519 - val_auc: 0.8242\n",
      "Epoch 5/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2932 - accuracy: 0.9100 - auc: 0.9546 - val_loss: 0.4357 - val_accuracy: 0.8569 - val_auc: 0.8378\n",
      "Epoch 6/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2935 - accuracy: 0.9115 - auc: 0.9526 - val_loss: 0.4481 - val_accuracy: 0.8500 - val_auc: 0.8225\n",
      "Epoch 7/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2902 - accuracy: 0.9146 - auc: 0.9569 - val_loss: 0.4270 - val_accuracy: 0.8500 - val_auc: 0.8353\n",
      "Epoch 8/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2920 - accuracy: 0.9123 - auc: 0.9536 - val_loss: 0.4298 - val_accuracy: 0.8537 - val_auc: 0.8345\n",
      "Epoch 9/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2909 - accuracy: 0.9147 - auc: 0.9560 - val_loss: 0.4367 - val_accuracy: 0.8525 - val_auc: 0.8288\n",
      "Epoch 10/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2893 - accuracy: 0.9138 - auc: 0.9560 - val_loss: 0.4397 - val_accuracy: 0.8519 - val_auc: 0.8202\n",
      "Epoch 11/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2893 - accuracy: 0.9158 - auc: 0.9558 - val_loss: 0.4418 - val_accuracy: 0.8550 - val_auc: 0.8191\n",
      "Epoch 12/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2876 - accuracy: 0.9137 - auc: 0.9569 - val_loss: 0.4476 - val_accuracy: 0.8531 - val_auc: 0.8280\n",
      "Epoch 13/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2888 - accuracy: 0.9133 - auc: 0.9579 - val_loss: 0.4398 - val_accuracy: 0.8606 - val_auc: 0.8150\n",
      "Epoch 14/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2868 - accuracy: 0.9196 - auc: 0.9591 - val_loss: 0.4469 - val_accuracy: 0.8537 - val_auc: 0.8288\n",
      "Epoch 15/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2887 - accuracy: 0.9168 - auc: 0.9563 - val_loss: 0.4312 - val_accuracy: 0.8550 - val_auc: 0.8332\n",
      "Epoch 16/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2864 - accuracy: 0.9168 - auc: 0.9566 - val_loss: 0.4367 - val_accuracy: 0.8456 - val_auc: 0.8405\n",
      "Epoch 17/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2864 - accuracy: 0.9166 - auc: 0.9584 - val_loss: 0.4316 - val_accuracy: 0.8544 - val_auc: 0.8363\n",
      "Epoch 18/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2843 - accuracy: 0.9185 - auc: 0.9611 - val_loss: 0.4319 - val_accuracy: 0.8519 - val_auc: 0.8326\n",
      "Epoch 19/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2867 - accuracy: 0.9165 - auc: 0.9579 - val_loss: 0.4369 - val_accuracy: 0.8569 - val_auc: 0.8347\n",
      "Epoch 20/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2850 - accuracy: 0.9189 - auc: 0.9597 - val_loss: 0.4412 - val_accuracy: 0.8544 - val_auc: 0.8217\n",
      "Epoch 21/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2839 - accuracy: 0.9181 - auc: 0.9617 - val_loss: 0.4357 - val_accuracy: 0.8512 - val_auc: 0.8332\n",
      "Epoch 22/32\n",
      "8954/8954 [==============================] - 62s 7ms/sample - loss: 0.2841 - accuracy: 0.9184 - auc: 0.9617 - val_loss: 0.4268 - val_accuracy: 0.8512 - val_auc: 0.8458\n",
      "Epoch 23/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2818 - accuracy: 0.9216 - auc: 0.9640 - val_loss: 0.4465 - val_accuracy: 0.8475 - val_auc: 0.8341\n",
      "Epoch 24/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2822 - accuracy: 0.9207 - auc: 0.9644 - val_loss: 0.4557 - val_accuracy: 0.8537 - val_auc: 0.8217\n",
      "Epoch 25/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2807 - accuracy: 0.9226 - auc: 0.9646 - val_loss: 0.4478 - val_accuracy: 0.8562 - val_auc: 0.8039\n",
      "Epoch 26/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2799 - accuracy: 0.9247 - auc: 0.9659 - val_loss: 0.4245 - val_accuracy: 0.8512 - val_auc: 0.8424\n",
      "Epoch 27/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2802 - accuracy: 0.9196 - auc: 0.9653 - val_loss: 0.4279 - val_accuracy: 0.8575 - val_auc: 0.8313\n",
      "Epoch 28/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2781 - accuracy: 0.9236 - auc: 0.9686 - val_loss: 0.4392 - val_accuracy: 0.8562 - val_auc: 0.8221\n",
      "Epoch 29/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2764 - accuracy: 0.9249 - auc: 0.9695 - val_loss: 0.4387 - val_accuracy: 0.8512 - val_auc: 0.8322\n",
      "Epoch 30/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2758 - accuracy: 0.9256 - auc: 0.9711 - val_loss: 0.4409 - val_accuracy: 0.8500 - val_auc: 0.8216\n",
      "Epoch 31/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2750 - accuracy: 0.9260 - auc: 0.9714 - val_loss: 0.4431 - val_accuracy: 0.8569 - val_auc: 0.8243\n",
      "Epoch 32/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2743 - accuracy: 0.9265 - auc: 0.9727 - val_loss: 0.4467 - val_accuracy: 0.8525 - val_auc: 0.8324\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/2\n",
      "8954/8954 [==============================] - 184s 21ms/sample - loss: 0.2755 - accuracy: 0.9255 - auc: 0.9716 - val_loss: 0.4239 - val_accuracy: 0.8556 - val_auc: 0.8452\n",
      "Epoch 2/2\n",
      "8954/8954 [==============================] - 158s 18ms/sample - loss: 0.2745 - accuracy: 0.9261 - auc: 0.9724 - val_loss: 0.4247 - val_accuracy: 0.8550 - val_auc: 0.8452\n",
      "Train ROC-AUC:\t 0.9442702184179457\n",
      "Valid ROC-AUC:\t 0.8459504330263924\n",
      "Train Accuracy:\t 0.91109375\n",
      "Valid Accuracy:\t 0.85125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      5432\n",
      "           1       0.75      0.62      0.68       968\n",
      "\n",
      "    accuracy                           0.91      6400\n",
      "   macro avg       0.84      0.79      0.81      6400\n",
      "weighted avg       0.91      0.91      0.91      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      1338\n",
      "           1       0.56      0.45      0.50       262\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.73      0.69      0.71      1600\n",
      "weighted avg       0.84      0.85      0.84      1600\n",
      "\n",
      "[INFO] ==================== FOLD# 2 ====================\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "6400/6400 [==============================] - 46s 7ms/sample - loss: 0.5321 - accuracy: 0.7905 - auc: 0.6079 - val_loss: 0.4690 - val_accuracy: 0.8438 - val_auc: 0.7129\n",
      "Epoch 2/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4591 - accuracy: 0.8466 - auc: 0.7505 - val_loss: 0.4606 - val_accuracy: 0.8487 - val_auc: 0.7604\n",
      "Epoch 3/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4400 - accuracy: 0.8528 - auc: 0.7916 - val_loss: 0.4497 - val_accuracy: 0.8325 - val_auc: 0.7872\n",
      "Epoch 4/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4317 - accuracy: 0.8603 - auc: 0.8106 - val_loss: 0.4441 - val_accuracy: 0.8494 - val_auc: 0.7821\n",
      "Epoch 5/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4240 - accuracy: 0.8661 - auc: 0.8262 - val_loss: 0.4593 - val_accuracy: 0.8550 - val_auc: 0.7721\n",
      "Epoch 6/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4190 - accuracy: 0.8633 - auc: 0.8354 - val_loss: 0.4437 - val_accuracy: 0.8487 - val_auc: 0.8003\n",
      "Epoch 7/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4164 - accuracy: 0.8656 - auc: 0.8441 - val_loss: 0.4392 - val_accuracy: 0.8500 - val_auc: 0.8022\n",
      "Epoch 8/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4157 - accuracy: 0.8661 - auc: 0.8433 - val_loss: 0.4421 - val_accuracy: 0.8537 - val_auc: 0.7869\n",
      "Epoch 9/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4120 - accuracy: 0.8680 - auc: 0.8504 - val_loss: 0.4375 - val_accuracy: 0.8637 - val_auc: 0.8103\n",
      "Epoch 10/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4079 - accuracy: 0.8697 - auc: 0.8576 - val_loss: 0.4372 - val_accuracy: 0.8606 - val_auc: 0.7971\n",
      "Epoch 11/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4029 - accuracy: 0.8708 - auc: 0.8672 - val_loss: 0.4408 - val_accuracy: 0.8600 - val_auc: 0.8120\n",
      "Epoch 12/32\n",
      "6400/6400 [==============================] - 44s 7ms/sample - loss: 0.4042 - accuracy: 0.8752 - auc: 0.8646 - val_loss: 0.4294 - val_accuracy: 0.8600 - val_auc: 0.8237\n",
      "Epoch 13/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4040 - accuracy: 0.8750 - auc: 0.8657 - val_loss: 0.4427 - val_accuracy: 0.8481 - val_auc: 0.8061\n",
      "Epoch 14/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4016 - accuracy: 0.8720 - auc: 0.8694 - val_loss: 0.4231 - val_accuracy: 0.8656 - val_auc: 0.8235\n",
      "Epoch 15/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3994 - accuracy: 0.8763 - auc: 0.8736 - val_loss: 0.4183 - val_accuracy: 0.8687 - val_auc: 0.8325\n",
      "Epoch 16/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3959 - accuracy: 0.8767 - auc: 0.8795 - val_loss: 0.4212 - val_accuracy: 0.8675 - val_auc: 0.8225\n",
      "Epoch 17/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3986 - accuracy: 0.8778 - auc: 0.8723 - val_loss: 0.4285 - val_accuracy: 0.8575 - val_auc: 0.8282\n",
      "Epoch 18/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3933 - accuracy: 0.8775 - auc: 0.8837 - val_loss: 0.4242 - val_accuracy: 0.8731 - val_auc: 0.8227\n",
      "Epoch 19/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3909 - accuracy: 0.8775 - auc: 0.8883 - val_loss: 0.4218 - val_accuracy: 0.8612 - val_auc: 0.8353\n",
      "Epoch 20/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3943 - accuracy: 0.8802 - auc: 0.8812 - val_loss: 0.4206 - val_accuracy: 0.8644 - val_auc: 0.8254\n",
      "Epoch 21/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3895 - accuracy: 0.8822 - auc: 0.8877 - val_loss: 0.4266 - val_accuracy: 0.8562 - val_auc: 0.8419\n",
      "Epoch 22/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3876 - accuracy: 0.8817 - auc: 0.8938 - val_loss: 0.4233 - val_accuracy: 0.8712 - val_auc: 0.8283\n",
      "Epoch 23/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3892 - accuracy: 0.8789 - auc: 0.8886 - val_loss: 0.4382 - val_accuracy: 0.8456 - val_auc: 0.8227\n",
      "Epoch 24/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3884 - accuracy: 0.8838 - auc: 0.8889 - val_loss: 0.4270 - val_accuracy: 0.8631 - val_auc: 0.8238\n",
      "Epoch 25/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3829 - accuracy: 0.8875 - auc: 0.8961 - val_loss: 0.4190 - val_accuracy: 0.8669 - val_auc: 0.8406\n",
      "Epoch 26/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3840 - accuracy: 0.8847 - auc: 0.8965 - val_loss: 0.4202 - val_accuracy: 0.8594 - val_auc: 0.8424\n",
      "Epoch 27/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3820 - accuracy: 0.8855 - auc: 0.8998 - val_loss: 0.4222 - val_accuracy: 0.8656 - val_auc: 0.8387\n",
      "Epoch 28/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3819 - accuracy: 0.8850 - auc: 0.8998 - val_loss: 0.4243 - val_accuracy: 0.8612 - val_auc: 0.8414\n",
      "Epoch 29/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3827 - accuracy: 0.8853 - auc: 0.9003 - val_loss: 0.4248 - val_accuracy: 0.8669 - val_auc: 0.8375\n",
      "Epoch 30/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3792 - accuracy: 0.8861 - auc: 0.9056 - val_loss: 0.4231 - val_accuracy: 0.8669 - val_auc: 0.8364\n",
      "Epoch 31/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3796 - accuracy: 0.8870 - auc: 0.9048 - val_loss: 0.4270 - val_accuracy: 0.8606 - val_auc: 0.8220\n",
      "Epoch 32/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3744 - accuracy: 0.8913 - auc: 0.9098 - val_loss: 0.4663 - val_accuracy: 0.8594 - val_auc: 0.8340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.937294346170936\n",
      "Valid ROC-AUC:\t 0.8424211310059926\n",
      "Train Accuracy:\t 0.9028125\n",
      "Valid Accuracy:\t 0.859375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      5416\n",
      "           1       0.75      0.55      0.64       984\n",
      "\n",
      "    accuracy                           0.90      6400\n",
      "   macro avg       0.84      0.76      0.79      6400\n",
      "weighted avg       0.90      0.90      0.90      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1354\n",
      "           1       0.56      0.39      0.46       246\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.73      0.67      0.69      1600\n",
      "weighted avg       0.84      0.86      0.85      1600\n",
      "\n",
      "PSUEDO_PROB_THRESH_HIGH 0.791\n",
      "PSUEDO_PROB_THRESH_LOW 0.008\n",
      "Number of psuedo samples available: 2554\n",
      "Psuedo Toxicity: 1277\n",
      "Counter({'tr': 14000, 'pt': 11012, 'ru': 10948, 'fr': 10920, 'it': 8494, 'es': 8438})\n",
      "Counter({'pt': 880, 'es': 574, 'tr': 457, 'fr': 337, 'it': 225, 'ru': 81})\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "8954/8954 [==============================] - 69s 8ms/sample - loss: 0.3286 - accuracy: 0.9169 - auc: 0.9642 - val_loss: 0.4178 - val_accuracy: 0.8669 - val_auc: 0.8434\n",
      "Epoch 2/32\n",
      "8954/8954 [==============================] - 61s 7ms/sample - loss: 0.2972 - accuracy: 0.9133 - auc: 0.9616 - val_loss: 0.4164 - val_accuracy: 0.8725 - val_auc: 0.8457\n",
      "Epoch 3/32\n",
      "8954/8954 [==============================] - 61s 7ms/sample - loss: 0.2885 - accuracy: 0.9181 - auc: 0.9610 - val_loss: 0.4156 - val_accuracy: 0.8694 - val_auc: 0.8485\n",
      "Epoch 4/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2852 - accuracy: 0.9197 - auc: 0.9629 - val_loss: 0.4178 - val_accuracy: 0.8675 - val_auc: 0.8438\n",
      "Epoch 5/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2850 - accuracy: 0.9156 - auc: 0.9644 - val_loss: 0.4170 - val_accuracy: 0.8681 - val_auc: 0.8450\n",
      "Epoch 6/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2852 - accuracy: 0.9208 - auc: 0.9641 - val_loss: 0.4176 - val_accuracy: 0.8694 - val_auc: 0.8425\n",
      "Epoch 7/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2836 - accuracy: 0.9220 - auc: 0.9643 - val_loss: 0.4201 - val_accuracy: 0.8631 - val_auc: 0.8348- loss: 0 - ETA: 1s - loss: 0.2826 - accuracy: 0.9216 - auc - ETA: 1s - loss: 0.2833 - \n",
      "Epoch 8/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2846 - accuracy: 0.9193 - auc: 0.9638 - val_loss: 0.4207 - val_accuracy: 0.8644 - val_auc: 0.8359\n",
      "Epoch 9/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2812 - accuracy: 0.9233 - auc: 0.9673 - val_loss: 0.4240 - val_accuracy: 0.8637 - val_auc: 0.8418\n",
      "Epoch 10/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2832 - accuracy: 0.9224 - auc: 0.9654 - val_loss: 0.4281 - val_accuracy: 0.8606 - val_auc: 0.8380\n",
      "Epoch 11/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2824 - accuracy: 0.9228 - auc: 0.9654 - val_loss: 0.4282 - val_accuracy: 0.8594 - val_auc: 0.8304\n",
      "Epoch 12/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2818 - accuracy: 0.9210 - auc: 0.9651 - val_loss: 0.4494 - val_accuracy: 0.8700 - val_auc: 0.8113\n",
      "Epoch 13/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2814 - accuracy: 0.9219 - auc: 0.9652 - val_loss: 0.4258 - val_accuracy: 0.8569 - val_auc: 0.8358\n",
      "Epoch 14/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2814 - accuracy: 0.9198 - auc: 0.9654 - val_loss: 0.4281 - val_accuracy: 0.8612 - val_auc: 0.8376\n",
      "Epoch 15/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2832 - accuracy: 0.9185 - auc: 0.9635 - val_loss: 0.4238 - val_accuracy: 0.8625 - val_auc: 0.8296\n",
      "Epoch 16/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2797 - accuracy: 0.9233 - auc: 0.9677 - val_loss: 0.4569 - val_accuracy: 0.8644 - val_auc: 0.8280 5s - loss: 0.2796 - accu - ETA: 4s - l -\n",
      "Epoch 17/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2802 - accuracy: 0.9237 - auc: 0.9668 - val_loss: 0.4550 - val_accuracy: 0.8319 - val_auc: 0.8443\n",
      "Epoch 18/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2813 - accuracy: 0.9189 - auc: 0.9653 - val_loss: 0.4290 - val_accuracy: 0.8506 - val_auc: 0.8407\n",
      "Epoch 19/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2803 - accuracy: 0.9234 - auc: 0.9666 - val_loss: 0.4264 - val_accuracy: 0.8525 - val_auc: 0.8419s: 0.2723 - ETA: 4s - loss: 0\n",
      "Epoch 20/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2786 - accuracy: 0.9241 - auc: 0.9690 - val_loss: 0.4369 - val_accuracy: 0.8587 - val_auc: 0.8358\n",
      "Epoch 21/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2801 - accuracy: 0.9220 - auc: 0.9677 - val_loss: 0.4440 - val_accuracy: 0.8456 - val_auc: 0.8206\n",
      "Epoch 22/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2786 - accuracy: 0.9265 - auc: 0.9684 - val_loss: 0.4570 - val_accuracy: 0.8331 - val_auc: 0.8025\n",
      "Epoch 23/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2786 - accuracy: 0.9239 - auc: 0.9670 - val_loss: 0.4307 - val_accuracy: 0.8500 - val_auc: 0.8425\n",
      "Epoch 24/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2785 - accuracy: 0.9209 - auc: 0.9688 - val_loss: 0.4398 - val_accuracy: 0.8656 - val_auc: 0.8372\n",
      "Epoch 25/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2761 - accuracy: 0.9247 - auc: 0.9703 - val_loss: 0.4252 - val_accuracy: 0.8569 - val_auc: 0.8395\n",
      "Epoch 26/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2766 - accuracy: 0.9255 - auc: 0.9705 - val_loss: 0.4245 - val_accuracy: 0.8519 - val_auc: 0.8452\n",
      "Epoch 27/32\n",
      "8954/8954 [==============================] - 61s 7ms/sample - loss: 0.2752 - accuracy: 0.9271 - auc: 0.9711 - val_loss: 0.4275 - val_accuracy: 0.8644 - val_auc: 0.8445\n",
      "Epoch 28/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2735 - accuracy: 0.9304 - auc: 0.9731 - val_loss: 0.4422 - val_accuracy: 0.8394 - val_auc: 0.8420\n",
      "Epoch 29/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2717 - accuracy: 0.9283 - auc: 0.9752 - val_loss: 0.4283 - val_accuracy: 0.8612 - val_auc: 0.8370oss: 0.2649 - - ETA: 26s - loss: 0.2645 - accuracy: 0.9323 - auc: 0.979 - ETA: 25s - loss: 0.2\n",
      "Epoch 30/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2716 - accuracy: 0.9329 - auc: 0.9750 - val_loss: 0.4347 - val_accuracy: 0.8500 - val_auc: 0.8324\n",
      "Epoch 31/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2700 - accuracy: 0.9340 - auc: 0.9764 - val_loss: 0.4282 - val_accuracy: 0.8644 - val_auc: 0.8408\n",
      "Epoch 32/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2688 - accuracy: 0.9331 - auc: 0.9774 - val_loss: 0.4271 - val_accuracy: 0.8562 - val_auc: 0.8396.2838 - accuracy:\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/2\n",
      "8954/8954 [==============================] - 169s 19ms/sample - loss: 0.2840 - accuracy: 0.9215 - auc: 0.9648 - val_loss: 0.4149 - val_accuracy: 0.8712 - val_auc: 0.8495\n",
      "Epoch 2/2\n",
      "8954/8954 [==============================] - 157s 18ms/sample - loss: 0.2853 - accuracy: 0.9169 - auc: 0.9653 - val_loss: 0.4145 - val_accuracy: 0.8706 - val_auc: 0.8482\n",
      "Train ROC-AUC:\t 0.9416723709334582\n",
      "Valid ROC-AUC:\t 0.8494223679312126\n",
      "Train Accuracy:\t 0.90125\n",
      "Valid Accuracy:\t 0.87125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5416\n",
      "           1       0.79      0.49      0.60       984\n",
      "\n",
      "    accuracy                           0.90      6400\n",
      "   macro avg       0.85      0.73      0.77      6400\n",
      "weighted avg       0.89      0.90      0.89      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1354\n",
      "           1       0.64      0.38      0.48       246\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.77      0.67      0.70      1600\n",
      "weighted avg       0.86      0.87      0.86      1600\n",
      "\n",
      "[INFO] ==================== FOLD# 3 ====================\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "6400/6400 [==============================] - 46s 7ms/sample - loss: 0.6503 - accuracy: 0.6795 - auc: 0.5040 - val_loss: 0.4949 - val_accuracy: 0.8413 - val_auc: 0.5850\n",
      "Epoch 2/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.5043 - accuracy: 0.8370 - auc: 0.5798 - val_loss: 0.4749 - val_accuracy: 0.8444 - val_auc: 0.6494\n",
      "Epoch 3/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4750 - accuracy: 0.8494 - auc: 0.6675 - val_loss: 0.4695 - val_accuracy: 0.8500 - val_auc: 0.6739\n",
      "Epoch 4/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4623 - accuracy: 0.8495 - auc: 0.7137 - val_loss: 0.4598 - val_accuracy: 0.8594 - val_auc: 0.7118\n",
      "Epoch 5/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4487 - accuracy: 0.8572 - auc: 0.7408 - val_loss: 0.4494 - val_accuracy: 0.8550 - val_auc: 0.7291\n",
      "Epoch 6/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4416 - accuracy: 0.8564 - auc: 0.7675 - val_loss: 0.4499 - val_accuracy: 0.8569 - val_auc: 0.7545\n",
      "Epoch 7/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4358 - accuracy: 0.8584 - auc: 0.7830 - val_loss: 0.4515 - val_accuracy: 0.8531 - val_auc: 0.7528\n",
      "Epoch 8/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4244 - accuracy: 0.8636 - auc: 0.8086 - val_loss: 0.4597 - val_accuracy: 0.8544 - val_auc: 0.7461\n",
      "Epoch 9/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.4249 - accuracy: 0.8597 - auc: 0.8148 - val_loss: 0.4527 - val_accuracy: 0.8556 - val_auc: 0.7688\n",
      "Epoch 10/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4156 - accuracy: 0.8686 - auc: 0.8305 - val_loss: 0.4480 - val_accuracy: 0.8575 - val_auc: 0.7763\n",
      "Epoch 11/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4143 - accuracy: 0.8694 - auc: 0.8332 - val_loss: 0.4262 - val_accuracy: 0.8719 - val_auc: 0.7963\n",
      "Epoch 12/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.4064 - accuracy: 0.8733 - auc: 0.8487 - val_loss: 0.4569 - val_accuracy: 0.8537 - val_auc: 0.7851\n",
      "Epoch 13/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4086 - accuracy: 0.8733 - auc: 0.8479 - val_loss: 0.4254 - val_accuracy: 0.8612 - val_auc: 0.8121\n",
      "Epoch 14/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4038 - accuracy: 0.8733 - auc: 0.8548 - val_loss: 0.4229 - val_accuracy: 0.8669 - val_auc: 0.8242\n",
      "Epoch 15/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3986 - accuracy: 0.8789 - auc: 0.8637 - val_loss: 0.4252 - val_accuracy: 0.8650 - val_auc: 0.8078\n",
      "Epoch 16/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3970 - accuracy: 0.8795 - auc: 0.8637 - val_loss: 0.4191 - val_accuracy: 0.8687 - val_auc: 0.8148\n",
      "Epoch 17/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3934 - accuracy: 0.8764 - auc: 0.8724 - val_loss: 0.4464 - val_accuracy: 0.8581 - val_auc: 0.8185\n",
      "Epoch 18/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3930 - accuracy: 0.8772 - auc: 0.8757 - val_loss: 0.4229 - val_accuracy: 0.8763 - val_auc: 0.8139\n",
      "Epoch 19/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3886 - accuracy: 0.8819 - auc: 0.8795 - val_loss: 0.4309 - val_accuracy: 0.8706 - val_auc: 0.7942\n",
      "Epoch 20/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3892 - accuracy: 0.8828 - auc: 0.8789 - val_loss: 0.4541 - val_accuracy: 0.8594 - val_auc: 0.8152\n",
      "Epoch 21/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3857 - accuracy: 0.8853 - auc: 0.8828 - val_loss: 0.4405 - val_accuracy: 0.8606 - val_auc: 0.8202\n",
      "Epoch 22/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3875 - accuracy: 0.8833 - auc: 0.8844 - val_loss: 0.4331 - val_accuracy: 0.8656 - val_auc: 0.8353\n",
      "Epoch 23/32\n",
      "6400/6400 [==============================] - 42s 7ms/sample - loss: 0.3845 - accuracy: 0.8844 - auc: 0.8867 - val_loss: 0.4278 - val_accuracy: 0.8644 - val_auc: 0.8404\n",
      "Epoch 24/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3828 - accuracy: 0.8867 - auc: 0.8904 - val_loss: 0.4380 - val_accuracy: 0.8587 - val_auc: 0.8329\n",
      "Epoch 25/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3824 - accuracy: 0.8873 - auc: 0.8902 - val_loss: 0.4531 - val_accuracy: 0.8575 - val_auc: 0.8406\n",
      "Epoch 26/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3777 - accuracy: 0.8925 - auc: 0.8952 - val_loss: 0.4131 - val_accuracy: 0.8750 - val_auc: 0.8395\n",
      "Epoch 27/32\n",
      "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3803 - accuracy: 0.8884 - auc: 0.8906 - val_loss: 0.4311 - val_accuracy: 0.8669 - val_auc: 0.8396\n",
      "Epoch 28/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3812 - accuracy: 0.8861 - auc: 0.8934 - val_loss: 0.4200 - val_accuracy: 0.8637 - val_auc: 0.8326\n",
      "Epoch 29/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3779 - accuracy: 0.8894 - auc: 0.8961 - val_loss: 0.4234 - val_accuracy: 0.8662 - val_auc: 0.8395\n",
      "Epoch 30/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3731 - accuracy: 0.8881 - auc: 0.9027 - val_loss: 0.4625 - val_accuracy: 0.8562 - val_auc: 0.8369\n",
      "Epoch 31/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3745 - accuracy: 0.8914 - auc: 0.8996 - val_loss: 0.4358 - val_accuracy: 0.8581 - val_auc: 0.8270\n",
      "Epoch 32/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3680 - accuracy: 0.8923 - auc: 0.9090 - val_loss: 0.4278 - val_accuracy: 0.8719 - val_auc: 0.8412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9484194647245849\n",
      "Valid ROC-AUC:\t 0.8416026436342812\n",
      "Train Accuracy:\t 0.90875\n",
      "Valid Accuracy:\t 0.871875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      5418\n",
      "           1       0.90      0.46      0.61       982\n",
      "\n",
      "    accuracy                           0.91      6400\n",
      "   macro avg       0.90      0.72      0.78      6400\n",
      "weighted avg       0.91      0.91      0.90      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1352\n",
      "           1       0.72      0.28      0.41       248\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.80      0.63      0.67      1600\n",
      "weighted avg       0.86      0.87      0.85      1600\n",
      "\n",
      "PSUEDO_PROB_THRESH_HIGH 0.839\n",
      "PSUEDO_PROB_THRESH_LOW 0.016\n",
      "Number of psuedo samples available: 2554\n",
      "Psuedo Toxicity: 1277\n",
      "Counter({'tr': 14000, 'pt': 11012, 'ru': 10948, 'fr': 10920, 'it': 8494, 'es': 8438})\n",
      "Counter({'tr': 817, 'es': 673, 'pt': 449, 'fr': 290, 'it': 242, 'ru': 83})\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "8954/8954 [==============================] - 69s 8ms/sample - loss: 0.2926 - accuracy: 0.9224 - auc: 0.9685 - val_loss: 0.4183 - val_accuracy: 0.8675 - val_auc: 0.8445\n",
      "Epoch 2/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2769 - accuracy: 0.9272 - auc: 0.9703 - val_loss: 0.4142 - val_accuracy: 0.8694 - val_auc: 0.8450\n",
      "Epoch 3/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2784 - accuracy: 0.9273 - auc: 0.9694 - val_loss: 0.4137 - val_accuracy: 0.8662 - val_auc: 0.8460\n",
      "Epoch 4/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2782 - accuracy: 0.9258 - auc: 0.9697 - val_loss: 0.4208 - val_accuracy: 0.8637 - val_auc: 0.8440\n",
      "Epoch 5/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2766 - accuracy: 0.9294 - auc: 0.9715 - val_loss: 0.4130 - val_accuracy: 0.8725 - val_auc: 0.8455\n",
      "Epoch 6/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2766 - accuracy: 0.9253 - auc: 0.9709 - val_loss: 0.4125 - val_accuracy: 0.8712 - val_auc: 0.8473\n",
      "Epoch 7/32\n",
      "8954/8954 [==============================] - 58s 6ms/sample - loss: 0.2757 - accuracy: 0.9291 - auc: 0.9713 - val_loss: 0.4159 - val_accuracy: 0.8650 - val_auc: 0.8427\n",
      "Epoch 8/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2725 - accuracy: 0.9295 - auc: 0.9734 - val_loss: 0.4278 - val_accuracy: 0.8681 - val_auc: 0.8393\n",
      "Epoch 9/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2731 - accuracy: 0.9331 - auc: 0.9729 - val_loss: 0.4121 - val_accuracy: 0.8681 - val_auc: 0.8468\n",
      "Epoch 10/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2730 - accuracy: 0.9287 - auc: 0.9727 - val_loss: 0.4204 - val_accuracy: 0.8681 - val_auc: 0.8429\n",
      "Epoch 11/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2726 - accuracy: 0.9310 - auc: 0.9728 - val_loss: 0.4136 - val_accuracy: 0.8687 - val_auc: 0.8452\n",
      "Epoch 12/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2733 - accuracy: 0.9275 - auc: 0.9730 - val_loss: 0.4117 - val_accuracy: 0.8694 - val_auc: 0.8473\n",
      "Epoch 13/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2757 - accuracy: 0.9279 - auc: 0.9707 - val_loss: 0.4205 - val_accuracy: 0.8662 - val_auc: 0.8424\n",
      "Epoch 14/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2729 - accuracy: 0.9292 - auc: 0.9717 - val_loss: 0.4146 - val_accuracy: 0.8706 - val_auc: 0.8459\n",
      "Epoch 15/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2746 - accuracy: 0.9281 - auc: 0.9718 - val_loss: 0.4134 - val_accuracy: 0.8694 - val_auc: 0.8395\n",
      "Epoch 16/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2734 - accuracy: 0.9254 - auc: 0.9713 - val_loss: 0.4120 - val_accuracy: 0.8731 - val_auc: 0.8441\n",
      "Epoch 17/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2735 - accuracy: 0.9277 - auc: 0.9718 - val_loss: 0.4208 - val_accuracy: 0.8675 - val_auc: 0.8396loss: 0.2736 - accuracy: 0.9280 - auc: \n",
      "Epoch 18/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2728 - accuracy: 0.9299 - auc: 0.9727 - val_loss: 0.4283 - val_accuracy: 0.8744 - val_auc: 0.8360\n",
      "Epoch 19/32\n",
      "8954/8954 [==============================] - 61s 7ms/sample - loss: 0.2717 - accuracy: 0.9274 - auc: 0.9723 - val_loss: 0.4166 - val_accuracy: 0.8700 - val_auc: 0.8359\n",
      "Epoch 20/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2720 - accuracy: 0.9302 - auc: 0.9722 - val_loss: 0.4118 - val_accuracy: 0.8750 - val_auc: 0.8458ss: 0.2729 - accuracy - ETA: 1s - loss: 0.2724 - accuracy: 0. - ETA: 1s - loss: 0.2712 - accura\n",
      "Epoch 21/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2730 - accuracy: 0.9311 - auc: 0.9718 - val_loss: 0.4182 - val_accuracy: 0.8669 - val_auc: 0.8419\n",
      "Epoch 22/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2714 - accuracy: 0.9296 - auc: 0.9731 - val_loss: 0.4200 - val_accuracy: 0.8681 - val_auc: 0.8396\n",
      "Epoch 23/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2719 - accuracy: 0.9292 - auc: 0.9729 - val_loss: 0.4241 - val_accuracy: 0.8681 - val_auc: 0.8387\n",
      "Epoch 24/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2740 - accuracy: 0.9289 - auc: 0.9701 - val_loss: 0.4198 - val_accuracy: 0.8737 - val_auc: 0.8355\n",
      "Epoch 25/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2697 - accuracy: 0.9352 - auc: 0.9740 - val_loss: 0.4192 - val_accuracy: 0.8737 - val_auc: 0.8335\n",
      "Epoch 26/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2688 - accuracy: 0.9309 - auc: 0.9754 - val_loss: 0.4204 - val_accuracy: 0.8744 - val_auc: 0.8239\n",
      "Epoch 27/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2709 - accuracy: 0.9292 - auc: 0.9734 - val_loss: 0.4290 - val_accuracy: 0.8681 - val_auc: 0.8229\n",
      "Epoch 28/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2666 - accuracy: 0.9339 - auc: 0.9775 - val_loss: 0.4309 - val_accuracy: 0.8669 - val_auc: 0.8314\n",
      "Epoch 29/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2660 - accuracy: 0.9378 - auc: 0.9781 - val_loss: 0.4305 - val_accuracy: 0.8719 - val_auc: 0.8407\n",
      "Epoch 30/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2632 - accuracy: 0.9377 - auc: 0.9801 - val_loss: 0.4216 - val_accuracy: 0.8706 - val_auc: 0.8415\n",
      "Epoch 31/32\n",
      "8954/8954 [==============================] - 64s 7ms/sample - loss: 0.2630 - accuracy: 0.9407 - auc: 0.9795 - val_loss: 0.4245 - val_accuracy: 0.8750 - val_auc: 0.8369\n",
      "Epoch 32/32\n",
      "8954/8954 [==============================] - 65s 7ms/sample - loss: 0.2608 - accuracy: 0.9436 - auc: 0.9818 - val_loss: 0.4283 - val_accuracy: 0.8725 - val_auc: 0.8355\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/2\n",
      "8954/8954 [==============================] - 175s 20ms/sample - loss: 0.2743 - accuracy: 0.9289 - auc: 0.9728 - val_loss: 0.4139 - val_accuracy: 0.8700 - val_auc: 0.8475\n",
      "Epoch 2/2\n",
      "8954/8954 [==============================] - 161s 18ms/sample - loss: 0.2700 - accuracy: 0.9334 - auc: 0.9743 - val_loss: 0.4141 - val_accuracy: 0.8706 - val_auc: 0.8477\n",
      "Train ROC-AUC:\t 0.9567882648093892\n",
      "Valid ROC-AUC:\t 0.8480357654132469\n",
      "Train Accuracy:\t 0.91234375\n",
      "Valid Accuracy:\t 0.870625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      5418\n",
      "           1       0.89      0.49      0.63       982\n",
      "\n",
      "    accuracy                           0.91      6400\n",
      "   macro avg       0.90      0.74      0.79      6400\n",
      "weighted avg       0.91      0.91      0.90      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1352\n",
      "           1       0.70      0.29      0.41       248\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.79      0.63      0.67      1600\n",
      "weighted avg       0.85      0.87      0.85      1600\n",
      "\n",
      "[INFO] ==================== FOLD# 4 ====================\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "6400/6400 [==============================] - 47s 7ms/sample - loss: 0.5606 - accuracy: 0.7588 - auc: 0.5908 - val_loss: 0.4680 - val_accuracy: 0.8444 - val_auc: 0.6979\n",
      "Epoch 2/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4787 - accuracy: 0.8352 - auc: 0.7079 - val_loss: 0.4461 - val_accuracy: 0.8631 - val_auc: 0.7488\n",
      "Epoch 3/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.4561 - accuracy: 0.8484 - auc: 0.7631 - val_loss: 0.4450 - val_accuracy: 0.8556 - val_auc: 0.7685\n",
      "Epoch 4/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.4472 - accuracy: 0.8534 - auc: 0.7846 - val_loss: 0.4262 - val_accuracy: 0.8675 - val_auc: 0.7990\n",
      "Epoch 5/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4356 - accuracy: 0.8552 - auc: 0.8116 - val_loss: 0.4416 - val_accuracy: 0.8687 - val_auc: 0.7983\n",
      "Epoch 6/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4291 - accuracy: 0.8580 - auc: 0.8241 - val_loss: 0.4368 - val_accuracy: 0.8662 - val_auc: 0.7969\n",
      "Epoch 7/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.4262 - accuracy: 0.8583 - auc: 0.8320 - val_loss: 0.4270 - val_accuracy: 0.8669 - val_auc: 0.8137\n",
      "Epoch 8/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.4183 - accuracy: 0.8680 - auc: 0.8446 - val_loss: 0.4164 - val_accuracy: 0.8644 - val_auc: 0.8198\n",
      "Epoch 9/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.4143 - accuracy: 0.8666 - auc: 0.8520 - val_loss: 0.4624 - val_accuracy: 0.8687 - val_auc: 0.8283\n",
      "Epoch 10/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4145 - accuracy: 0.8687 - auc: 0.8499 - val_loss: 0.4245 - val_accuracy: 0.8650 - val_auc: 0.8202\n",
      "Epoch 11/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4110 - accuracy: 0.8694 - auc: 0.8569 - val_loss: 0.4183 - val_accuracy: 0.8594 - val_auc: 0.8310\n",
      "Epoch 12/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.4070 - accuracy: 0.8723 - auc: 0.8643 - val_loss: 0.4203 - val_accuracy: 0.8763 - val_auc: 0.8106\n",
      "Epoch 13/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4093 - accuracy: 0.8684 - auc: 0.8609 - val_loss: 0.4085 - val_accuracy: 0.8694 - val_auc: 0.8370\n",
      "Epoch 14/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.4046 - accuracy: 0.8737 - auc: 0.8686 - val_loss: 0.4081 - val_accuracy: 0.8763 - val_auc: 0.8416\n",
      "Epoch 15/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.4031 - accuracy: 0.8742 - auc: 0.8708 - val_loss: 0.4157 - val_accuracy: 0.8694 - val_auc: 0.8464\n",
      "Epoch 16/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3997 - accuracy: 0.8750 - auc: 0.8783 - val_loss: 0.4415 - val_accuracy: 0.8506 - val_auc: 0.8469\n",
      "Epoch 17/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3990 - accuracy: 0.8752 - auc: 0.8786 - val_loss: 0.4051 - val_accuracy: 0.8731 - val_auc: 0.8452\n",
      "Epoch 18/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3982 - accuracy: 0.8756 - auc: 0.8808 - val_loss: 0.4075 - val_accuracy: 0.8769 - val_auc: 0.8477\n",
      "Epoch 19/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3940 - accuracy: 0.8797 - auc: 0.8850 - val_loss: 0.4078 - val_accuracy: 0.8794 - val_auc: 0.8380\n",
      "Epoch 20/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3934 - accuracy: 0.8789 - auc: 0.8858 - val_loss: 0.4252 - val_accuracy: 0.8619 - val_auc: 0.8397\n",
      "Epoch 21/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3907 - accuracy: 0.8847 - auc: 0.8884 - val_loss: 0.4073 - val_accuracy: 0.8800 - val_auc: 0.8414\n",
      "Epoch 22/32\n",
      "6400/6400 [==============================] - 40s 6ms/sample - loss: 0.3901 - accuracy: 0.8825 - auc: 0.8918 - val_loss: 0.4062 - val_accuracy: 0.8731 - val_auc: 0.8529\n",
      "Epoch 23/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3878 - accuracy: 0.8825 - auc: 0.8927 - val_loss: 0.4140 - val_accuracy: 0.8606 - val_auc: 0.8402\n",
      "Epoch 24/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3913 - accuracy: 0.8803 - auc: 0.8909 - val_loss: 0.4052 - val_accuracy: 0.8831 - val_auc: 0.8478\n",
      "Epoch 25/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3863 - accuracy: 0.8841 - auc: 0.8980 - val_loss: 0.4144 - val_accuracy: 0.8637 - val_auc: 0.8497\n",
      "Epoch 26/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3875 - accuracy: 0.8861 - auc: 0.8946 - val_loss: 0.4008 - val_accuracy: 0.8800 - val_auc: 0.8443\n",
      "Epoch 27/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3851 - accuracy: 0.8881 - auc: 0.8969 - val_loss: 0.4027 - val_accuracy: 0.8769 - val_auc: 0.8495\n",
      "Epoch 28/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3857 - accuracy: 0.8867 - auc: 0.8968 - val_loss: 0.4032 - val_accuracy: 0.8756 - val_auc: 0.8511\n",
      "Epoch 29/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3809 - accuracy: 0.8902 - auc: 0.9032 - val_loss: 0.4023 - val_accuracy: 0.8725 - val_auc: 0.8496\n",
      "Epoch 30/32\n",
      "6400/6400 [==============================] - 41s 6ms/sample - loss: 0.3833 - accuracy: 0.8873 - auc: 0.9007 - val_loss: 0.3989 - val_accuracy: 0.8769 - val_auc: 0.8554\n",
      "Epoch 31/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3802 - accuracy: 0.8884 - auc: 0.9056 - val_loss: 0.4337 - val_accuracy: 0.8444 - val_auc: 0.8398\n",
      "Epoch 32/32\n",
      "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3780 - accuracy: 0.8903 - auc: 0.9086 - val_loss: 0.4249 - val_accuracy: 0.8569 - val_auc: 0.8484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC:\t 0.9532865581745419\n",
      "Valid ROC-AUC:\t 0.8552613687748823\n",
      "Train Accuracy:\t 0.9153125\n",
      "Valid Accuracy:\t 0.876875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      5401\n",
      "           1       0.82      0.58      0.68       999\n",
      "\n",
      "    accuracy                           0.92      6400\n",
      "   macro avg       0.87      0.78      0.82      6400\n",
      "weighted avg       0.91      0.92      0.91      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1369\n",
      "           1       0.60      0.43      0.50       231\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.76      0.69      0.72      1600\n",
      "weighted avg       0.86      0.88      0.87      1600\n",
      "\n",
      "PSUEDO_PROB_THRESH_HIGH 0.79\n",
      "PSUEDO_PROB_THRESH_LOW 0.013\n",
      "Number of psuedo samples available: 2554\n",
      "Psuedo Toxicity: 1277\n",
      "Counter({'tr': 14000, 'pt': 11012, 'ru': 10948, 'fr': 10920, 'it': 8494, 'es': 8438})\n",
      "Counter({'tr': 657, 'es': 628, 'fr': 519, 'ru': 266, 'pt': 251, 'it': 233})\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 8954 samples, validate on 1600 samples\n",
      "Epoch 1/32\n",
      "8954/8954 [==============================] - 68s 8ms/sample - loss: 0.3153 - accuracy: 0.9187 - auc: 0.9685 - val_loss: 0.3950 - val_accuracy: 0.8744 - val_auc: 0.8596\n",
      "Epoch 2/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2890 - accuracy: 0.9170 - auc: 0.9676 - val_loss: 0.3917 - val_accuracy: 0.8769 - val_auc: 0.8635\n",
      "Epoch 3/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2832 - accuracy: 0.9203 - auc: 0.9680 - val_loss: 0.3955 - val_accuracy: 0.8756 - val_auc: 0.8611\n",
      "Epoch 4/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2844 - accuracy: 0.9226 - auc: 0.9652 - val_loss: 0.3978 - val_accuracy: 0.8781 - val_auc: 0.8574\n",
      "Epoch 5/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2818 - accuracy: 0.9233 - auc: 0.9682 - val_loss: 0.4029 - val_accuracy: 0.8737 - val_auc: 0.8527\n",
      "Epoch 6/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2817 - accuracy: 0.9235 - auc: 0.9677 - val_loss: 0.3969 - val_accuracy: 0.8763 - val_auc: 0.8623\n",
      "Epoch 7/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2799 - accuracy: 0.9232 - auc: 0.9692 - val_loss: 0.4032 - val_accuracy: 0.8700 - val_auc: 0.8545\n",
      "Epoch 8/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2795 - accuracy: 0.9237 - auc: 0.9682 - val_loss: 0.3964 - val_accuracy: 0.8750 - val_auc: 0.8555\n",
      "Epoch 9/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2775 - accuracy: 0.9272 - auc: 0.9703 - val_loss: 0.4027 - val_accuracy: 0.8825 - val_auc: 0.8487\n",
      "Epoch 10/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2779 - accuracy: 0.9235 - auc: 0.9709 - val_loss: 0.4166 - val_accuracy: 0.8806 - val_auc: 0.8541\n",
      "Epoch 11/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2784 - accuracy: 0.9254 - auc: 0.9693 - val_loss: 0.4051 - val_accuracy: 0.8781 - val_auc: 0.8490 - ETA: 4s - loss: 0.2757 - ac - ETA: 3s - loss: 0.2773  - ETA: 2s -\n",
      "Epoch 12/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2784 - accuracy: 0.9232 - auc: 0.9699 - val_loss: 0.3959 - val_accuracy: 0.8819 - val_auc: 0.8565\n",
      "Epoch 13/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2786 - accuracy: 0.9247 - auc: 0.9706 - val_loss: 0.4058 - val_accuracy: 0.8731 - val_auc: 0.8473\n",
      "Epoch 14/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2785 - accuracy: 0.9246 - auc: 0.9686 - val_loss: 0.4067 - val_accuracy: 0.8756 - val_auc: 0.8371\n",
      "Epoch 15/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2785 - accuracy: 0.9237 - auc: 0.9702 - val_loss: 0.4709 - val_accuracy: 0.8294 - val_auc: 0.8487\n",
      "Epoch 16/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2788 - accuracy: 0.9233 - auc: 0.9687 - val_loss: 0.4013 - val_accuracy: 0.8744 - val_auc: 0.8514\n",
      "Epoch 17/32\n",
      "8954/8954 [==============================] - 60s 7ms/sample - loss: 0.2764 - accuracy: 0.9252 - auc: 0.9718 - val_loss: 0.4652 - val_accuracy: 0.8313 - val_auc: 0.8364\n",
      "Epoch 18/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2768 - accuracy: 0.9245 - auc: 0.9691 - val_loss: 0.3998 - val_accuracy: 0.8806 - val_auc: 0.8495\n",
      "Epoch 19/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2763 - accuracy: 0.9267 - auc: 0.9713 - val_loss: 0.4087 - val_accuracy: 0.8750 - val_auc: 0.8353\n",
      "Epoch 20/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2798 - accuracy: 0.9213 - auc: 0.9667 - val_loss: 0.3970 - val_accuracy: 0.8819 - val_auc: 0.8494\n",
      "Epoch 21/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2763 - accuracy: 0.9274 - auc: 0.9709 - val_loss: 0.4019 - val_accuracy: 0.8844 - val_auc: 0.8438\n",
      "Epoch 22/32\n",
      "8954/8954 [==============================] - 58s 7ms/sample - loss: 0.2781 - accuracy: 0.9251 - auc: 0.9696 - val_loss: 0.4067 - val_accuracy: 0.8806 - val_auc: 0.8531\n",
      "Epoch 23/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2757 - accuracy: 0.9262 - auc: 0.9702 - val_loss: 0.3980 - val_accuracy: 0.8800 - val_auc: 0.8526\n",
      "Epoch 24/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2757 - accuracy: 0.9275 - auc: 0.9714 - val_loss: 0.3939 - val_accuracy: 0.8769 - val_auc: 0.8598\n",
      "Epoch 25/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2744 - accuracy: 0.9281 - auc: 0.9727 - val_loss: 0.4039 - val_accuracy: 0.8838 - val_auc: 0.8385\n",
      "Epoch 26/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2717 - accuracy: 0.9273 - auc: 0.9756 - val_loss: 0.4038 - val_accuracy: 0.8763 - val_auc: 0.8409\n",
      "Epoch 27/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2730 - accuracy: 0.9275 - auc: 0.9737 - val_loss: 0.4320 - val_accuracy: 0.8500 - val_auc: 0.8459\n",
      "Epoch 28/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2731 - accuracy: 0.9310 - auc: 0.9733 - val_loss: 0.4027 - val_accuracy: 0.8681 - val_auc: 0.8523\n",
      "Epoch 29/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2690 - accuracy: 0.9335 - auc: 0.9777 - val_loss: 0.3947 - val_accuracy: 0.8819 - val_auc: 0.8538\n",
      "Epoch 30/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2658 - accuracy: 0.9399 - auc: 0.9811 - val_loss: 0.4387 - val_accuracy: 0.8425 - val_auc: 0.8429\n",
      "Epoch 31/32\n",
      "8954/8954 [==============================] - 59s 7ms/sample - loss: 0.2666 - accuracy: 0.9352 - auc: 0.9800 - val_loss: 0.4049 - val_accuracy: 0.8775 - val_auc: 0.8571\n",
      "Epoch 32/32\n",
      "2768/8954 [========>.....................] - ETA: 35s - loss: 0.2720 - accuracy: 0.9317 - auc: 0.9818- ETA: 50s - loss - ETA: 35s - loss: 0.2717 - accuracy: 0.9320 - auc: 0.98"
     ]
    }
   ],
   "source": [
    "for num, (t_index, v_index) in enumerate(kf.split(X_tokens, Y_toxic)):\n",
    "    print(\"[INFO] ==================== FOLD#\", num, \"====================\")\n",
    "    \n",
    "    start_time = time()\n",
    "\n",
    "    if num>0:\n",
    "        del model\n",
    "        del mcp\n",
    "        del csvl\n",
    "        del adam\n",
    "        del history\n",
    "        del auc\n",
    "        del tclr\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "\n",
    "    model = build_model()\n",
    "    auc = tf.keras.metrics.AUC(name='auc')\n",
    "    mcp = ModelCheckpoint(filepath=RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+str(num)+\".h5\", monitor='val_auc',\n",
    "                          verbose=0, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')\n",
    "    csvl = CSVLogger(filename=RESULTS_DIR+MODEL_PREFIX+\"_LossLogs_\"+str(num)+\".csv\",\n",
    "                     separator=\",\", append=True)\n",
    "    tclr = tfa.optimizers.TriangularCyclicalLearningRate(\n",
    "        initial_learning_rate=MIN_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        step_size=STEP_SIZE*len(t_index)\n",
    "    )\n",
    "\n",
    "    model.layers[2].trainable = False\n",
    "    adam = Adam(learning_rate=tclr)\n",
    "    model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy', auc])\n",
    "\n",
    "    train_time = time()\n",
    "    history = model.fit(x={\"att_flags\":X_att[t_index],\n",
    "                           \"words\":X_tokens[t_index]},\n",
    "                        y={\"toxic_output\":Y_toxic[t_index]},\n",
    "                        validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                          \"words\":X_tokens[v_index]},\n",
    "                                         {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=NUM_EPOCHS[0],\n",
    "                        shuffle=True,\n",
    "                        verbose=1, \n",
    "                        sample_weight=class_weight.compute_sample_weight('balanced', X_lang[t_index]),\n",
    "                        callbacks=[mcp, csvl])\n",
    "\n",
    "    # Loading best weights per fold\n",
    "    model.load_weights(RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+str(num)+\".h5\")\n",
    "    \n",
    "    pred_initial = model.predict(x = {\"att_flags\":X_att,\n",
    "                                      \"words\":X_tokens},\n",
    "                                 batch_size=PREDICT_BATCH_SIZE)\n",
    "    \n",
    "    pred_df['fold_'+str(num)] = 0\n",
    "    pred_df['fold_'+str(num)].iloc[t_index] = 'train'\n",
    "    pred_df['fold_'+str(num)].iloc[v_index] = 'valid'\n",
    "    pred_df['initial_'+str(num)] = pred_initial\n",
    "    \n",
    "    roc_t = roc_auc_score(y_true=Y_toxic[t_index], y_score=pred_initial[t_index])\n",
    "    roc_v = roc_auc_score(y_true=Y_toxic[v_index], y_score=pred_initial[v_index])\n",
    "    acc_t = accuracy_score(y_true=Y_toxic[t_index], y_pred=np.where(pred_initial[t_index]>0.5, 1, 0))\n",
    "    acc_v = accuracy_score(y_true=Y_toxic[v_index], y_pred=np.where(pred_initial[v_index]>0.5, 1, 0))\n",
    "    \n",
    "    print(\"Train ROC-AUC:\\t\", roc_t)\n",
    "    print(\"Valid ROC-AUC:\\t\", roc_v)\n",
    "    print(\"Train Accuracy:\\t\", acc_t)\n",
    "    print(\"Valid Accuracy:\\t\", acc_v)\n",
    "\n",
    "    print(classification_report(y_true=Y_toxic[t_index], y_pred=np.where(pred_initial[t_index]>0.5, 1, 0)))\n",
    "    print(classification_report(y_true=Y_toxic[v_index], y_pred=np.where(pred_initial[v_index]>0.5, 1, 0)))\n",
    "\n",
    "    # Psuedo model fit\n",
    "    psuedo_time = time()\n",
    "\n",
    "    # Accumulate test results after training every fold\n",
    "    pred_psuedo = model.predict(x = {\"att_flags\":X_att_test,\n",
    "                                     \"words\":X_tokens_test},\n",
    "                                batch_size=PREDICT_BATCH_SIZE).reshape((-1))\n",
    "\n",
    "    pred_df_test['psuedo_'+str(num)] = pred_psuedo\n",
    "    PSUEDO_PROB_THRESH_HIGH = pred_df_test['psuedo_'+str(num)].quantile(PSUEDO_QUANTILE_THRESH_HIGH)\n",
    "    PSUEDO_PROB_THRESH_LOW = pred_df_test['psuedo_'+str(num)].quantile(PSUEDO_QUANTILE_THRESH_LOW)\n",
    "    \n",
    "    print(\"PSUEDO_PROB_THRESH_HIGH\", np.round(PSUEDO_PROB_THRESH_HIGH,3))\n",
    "    print(\"PSUEDO_PROB_THRESH_LOW\", np.round(PSUEDO_PROB_THRESH_LOW,3))\n",
    "\n",
    "    Y_toxic_psuedo = np.where(pred_psuedo >= PSUEDO_PROB_THRESH_HIGH, 1, 0)\n",
    "    psuedo_flag = (pred_psuedo >= PSUEDO_PROB_THRESH_HIGH) | (pred_psuedo <= PSUEDO_PROB_THRESH_LOW)\n",
    "\n",
    "    print(\"Number of psuedo samples available:\", sum(psuedo_flag))\n",
    "    print(\"Psuedo Toxicity:\", sum(Y_toxic_psuedo))\n",
    "    print(Counter(test.lang.values))\n",
    "    print(Counter(test.lang.values[psuedo_flag]))\n",
    "\n",
    "    X_att_psuedo = np.concatenate((X_att[t_index], X_att_test[psuedo_flag]))\n",
    "    X_tokens_psuedo = np.concatenate((X_tokens[t_index], X_tokens_test[psuedo_flag]))\n",
    "    Y_toxic_psuedo = np.concatenate((Y_toxic[t_index], Y_toxic_psuedo[psuedo_flag]))\n",
    "    X_lang_psuedo = np.concatenate((X_lang[t_index], X_lang_test[psuedo_flag]))\n",
    "\n",
    "    shuffled_idxs = np.arange(Y_toxic_psuedo.shape[0])\n",
    "    np.random.shuffle(shuffled_idxs)\n",
    "\n",
    "    model.layers[2].trainable = False\n",
    "    adam = Adam(learning_rate=tclr)\n",
    "    model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy', auc])\n",
    "\n",
    "    history = model.fit(x={\"att_flags\":X_att_psuedo[shuffled_idxs],\n",
    "                           \"words\":X_tokens_psuedo[shuffled_idxs]},\n",
    "                        y={\"toxic_output\":Y_toxic_psuedo[shuffled_idxs]},\n",
    "                        validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                          \"words\":X_tokens[v_index]},\n",
    "                                         {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=NUM_EPOCHS[1],\n",
    "                        shuffle=True,\n",
    "                        verbose=1,\n",
    "                        callbacks=[mcp, csvl], \n",
    "                        sample_weight=class_weight.compute_sample_weight('balanced', X_lang_psuedo[shuffled_idxs]))\n",
    "\n",
    "    # Loading best weights per fold\n",
    "    model.load_weights(RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+str(num)+\".h5\")\n",
    "    \n",
    "    if NUM_EPOCHS[2]>0:\n",
    "        model.layers[2].trainable = True\n",
    "        adam = Adam(learning_rate=MIN_LR*0.1)\n",
    "        model.compile(loss={\"toxic_output\":tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING_PARAM)},\n",
    "                      optimizer=adam,\n",
    "                      metrics=['accuracy', auc])\n",
    "\n",
    "        history = model.fit(x={\"att_flags\":X_att_psuedo[shuffled_idxs],\n",
    "                               \"words\":X_tokens_psuedo[shuffled_idxs]},\n",
    "                            y={\"toxic_output\":Y_toxic_psuedo[shuffled_idxs]},\n",
    "                            validation_data=({\"att_flags\":X_att[v_index],\n",
    "                                              \"words\":X_tokens[v_index]},\n",
    "                                             {\"toxic_output\":Y_toxic[v_index]}),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=NUM_EPOCHS[2],\n",
    "                            shuffle=True,\n",
    "                            verbose=1,\n",
    "                            callbacks=[mcp, csvl], \n",
    "                            sample_weight=class_weight.compute_sample_weight('balanced',X_lang_psuedo[shuffled_idxs]))\n",
    "\n",
    "    infer_time = time()\n",
    "\n",
    "    # Loading best weights per fold\n",
    "    model.load_weights(RESULTS_DIR+MODEL_PREFIX+\"BestCheckpoint_\"+str(num)+\".h5\")\n",
    "\n",
    "    pred = model.predict(x = {\"att_flags\":X_att,\n",
    "                                    \"words\":X_tokens},\n",
    "                               batch_size=PREDICT_BATCH_SIZE)\n",
    "    \n",
    "    pred_df['final_'+str(num)] = pred\n",
    "\n",
    "    final_roc_t = roc_auc_score(y_true=Y_toxic[t_index], y_score=pred[t_index])\n",
    "    final_roc_v = roc_auc_score(y_true=Y_toxic[v_index], y_score=pred[v_index])\n",
    "    final_acc_t = accuracy_score(y_true=Y_toxic[t_index], y_pred=np.where(pred[t_index]>0.5, 1, 0))\n",
    "    final_acc_v = accuracy_score(y_true=Y_toxic[v_index], y_pred=np.where(pred[v_index]>0.5, 1, 0))    \n",
    "    \n",
    "    print(\"Train ROC-AUC:\\t\", final_roc_t)\n",
    "    print(\"Valid ROC-AUC:\\t\", final_roc_v)\n",
    "    print(\"Train Accuracy:\\t\", final_acc_t)\n",
    "    print(\"Valid Accuracy:\\t\", final_acc_v)\n",
    "\n",
    "    print(classification_report(y_true=Y_toxic[t_index], y_pred=np.where(pred[t_index]>0.5, 1, 0)))\n",
    "    print(classification_report(y_true=Y_toxic[v_index], y_pred=np.where(pred[v_index]>0.5, 1, 0)))\n",
    "\n",
    "    # Accumulate test results after training every fold\n",
    "\n",
    "    pred_test = model.predict(x = {\"att_flags\":X_att_test,\n",
    "                                    \"words\":X_tokens_test},\n",
    "                               batch_size=PREDICT_BATCH_SIZE)\n",
    "    \n",
    "    pred_df_test['final_'+str(num)] = pred_test\n",
    "\n",
    "    end_time = time()\n",
    "    timings_dict.update({num:{\n",
    "        'start_time' : ctime(start_time),\n",
    "        'train_time' : ctime(train_time),\n",
    "        'infer_time' : ctime(infer_time),\n",
    "        'psuedo_time' : ctime(psuedo_time),\n",
    "        'end_time' : ctime(end_time),\n",
    "    }})\n",
    "    \n",
    "    cv_stats.update({num:{\n",
    "        'preliminary_roc_t':roc_t,\n",
    "        'final_roc_t':final_roc_t,\n",
    "        'preliminary_roc_v':roc_v,\n",
    "        'final_roc_v':final_roc_v,\n",
    "        'preliminary_acc_t':acc_t,\n",
    "        'final_acc_t':final_acc_t,\n",
    "        'preliminary_acc_v':acc_v,\n",
    "        'final_acc_v':final_acc_v,\n",
    "    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(timings_dict).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['toxic_pred'] = pred_df[[i for i in pred_df_test.columns if i.startswith('final')]].mean(axis=1)\n",
    "pred_df_test['toxic'] = pred_df_test[[i for i in pred_df_test.columns if i.startswith('final')]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_test[['id','toxic']].to_csv(RESULTS_DIR+\"submission.csv\", index=False)\n",
    "pred_df_test.to_csv(RESULTS_DIR+\"all_test_results_\"+MODEL_PREFIX+\".csv\", index=False)\n",
    "pred_df.to_csv(RESULTS_DIR+\"all_results_\"+MODEL_PREFIX+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_group = pd.concat((data, pred_df), axis=1).groupby(['lang'])\n",
    "lang_group[['toxic','toxic_pred']].apply(lambda x: pd.Series({'roc':roc_auc_score(y_true=x.toxic,\n",
    "                                                                                  y_score=x.toxic_pred), \n",
    "                                                              'acc':accuracy_score(y_true=np.round(x.toxic),\n",
    "                                                                                   y_pred=np.round(x.toxic_pred).astype(int))})).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_test['toxic'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_test.groupby(test['lang'])[['toxic']].apply(pd.Series.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mr6qXyMSR6d6"
   },
   "outputs": [],
   "source": [
    "print(ctime(time()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
